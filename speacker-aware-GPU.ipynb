{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4100183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ydata-profiling demoji nltk scikit-learn gensim  textblob spacy textstat transformers torch seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe5d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from ydata_profiling import ProfileReport\n",
    "from textstat import flesch_reading_ease  # exploring text complixity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertTokenizer, AdamW\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0030706",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5205990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all_data.jsonl already exists.\n"
     ]
    }
   ],
   "source": [
    "# download deplomacy dataset\n",
    "if os.path.exists(os.path.join(folder_path,'all_data.jsonl')) :\n",
    "    print(f\" all_data.jsonl already exists.\") \n",
    "else:\n",
    "    for i in ['train.jsonl', 'test.jsonl', 'validation.jsonl']:\n",
    "        filename = os.path.join(folder_path, i)\n",
    "        #if os.path.exists(filename):\n",
    "            #print(f\" File {filename} already exists.\")\n",
    "        #else:\n",
    "        url = \"https://github.com/DenisPeskov/2020_acl_diplomacy/raw/master/data/\"+i\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # join all three files into a file \n",
    "            with open(folder_path + '/all_data.jsonl', 'ab') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"File '{filename}' added to all_data file.\")\n",
    "        else:\n",
    "            print(f\"Failed to download {url}. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5eabb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " File data/full_dialog.csv already exists.\n"
     ]
    }
   ],
   "source": [
    "# download persuasion for good dataset\n",
    "filename = os.path.join(folder_path, \"full_dialog.csv\")\n",
    "if os.path.exists(filename):\n",
    "    print(f\" File {filename} already exists.\")\n",
    "else:\n",
    "    url = \"https://gitlab.com/ucdavisnlp/persuasionforgood/-/raw/master/data/FullData/full_dialog.csv?inline=false\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File '{filename}' has been downloaded and saved to '{folder_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f918d401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sender_labels</th>\n",
       "      <th>receiver_labels</th>\n",
       "      <th>speakers</th>\n",
       "      <th>receivers</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>seasons</th>\n",
       "      <th>years</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>players</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Germany!\\n\\nJust the person I want to speak w...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[True, True, True, True, NOANNOTATION, NOANNOT...</td>\n",
       "      <td>[italy, germany, italy, germany, italy, italy,...</td>\n",
       "      <td>[germany, italy, germany, italy, germany, germ...</td>\n",
       "      <td>[74, 76, 86, 87, 89, 92, 97, 117, 119, 121, 12...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[italy, germany]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hello there! What's your general plan for thi...</td>\n",
       "      <td>[True, False, True, False, True, True, True, T...</td>\n",
       "      <td>[True, True, True, True, True, NOANNOTATION, T...</td>\n",
       "      <td>[austria, italy, austria, italy, italy, austri...</td>\n",
       "      <td>[italy, austria, italy, austria, austria, ital...</td>\n",
       "      <td>[1, 67, 71, 73, 98, 99, 101, 179, 181, 185, 18...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 4, 4, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, -...</td>\n",
       "      <td>[italy, austria]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  [Germany!\\n\\nJust the person I want to speak w...   \n",
       "1  [Hello there! What's your general plan for thi...   \n",
       "\n",
       "                                       sender_labels  \\\n",
       "0  [True, True, True, True, True, True, True, Tru...   \n",
       "1  [True, False, True, False, True, True, True, T...   \n",
       "\n",
       "                                     receiver_labels  \\\n",
       "0  [True, True, True, True, NOANNOTATION, NOANNOT...   \n",
       "1  [True, True, True, True, True, NOANNOTATION, T...   \n",
       "\n",
       "                                            speakers  \\\n",
       "0  [italy, germany, italy, germany, italy, italy,...   \n",
       "1  [austria, italy, austria, italy, italy, austri...   \n",
       "\n",
       "                                           receivers  \\\n",
       "0  [germany, italy, germany, italy, germany, germ...   \n",
       "1  [italy, austria, italy, austria, austria, ital...   \n",
       "\n",
       "                              absolute_message_index  \\\n",
       "0  [74, 76, 86, 87, 89, 92, 97, 117, 119, 121, 12...   \n",
       "1  [1, 67, 71, 73, 98, 99, 101, 179, 181, 185, 18...   \n",
       "\n",
       "                              relative_message_index  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                             seasons  \\\n",
       "0  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "1  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "\n",
       "                                               years  \\\n",
       "0  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "1  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "\n",
       "                                          game_score  \\\n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "1  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 4, 4, ...   \n",
       "\n",
       "                                    game_score_delta           players  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [italy, germany]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, -...  [italy, austria]   \n",
       "\n",
       "   game_id  \n",
       "0        1  \n",
       "1        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diplomacy= pd.read_json('data/all_data.jsonl', lines=True)\n",
    "diplomacy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1981cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Row:  9\n",
      "Empty Row:  62\n",
      "Empty Row:  87\n",
      "Empty Row:  96\n",
      "Empty Row:  188\n",
      "Empty Row:  249\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246 entries, 0 to 245\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   conversation  246 non-null    object\n",
      " 1   A_bad_intent  246 non-null    int64 \n",
      " 2   B_bad_intent  246 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "token = '[SEP]' # the seperator token for BERT\n",
    "conversations = []\n",
    "\n",
    "for i, j in diplomacy.iterrows(): \n",
    "    players = j['players']\n",
    "    if(len(j['messages']) == 0):\n",
    "        print(\"Empty Row: \" , i)\n",
    "        continue\n",
    "    message = '[CLS]'\n",
    "    for c, d in enumerate(j['messages']):       \n",
    "        if (j['speakers'][c] == players[0]):\n",
    "            message += 'A:' + j['messages'][c] + token\n",
    "        if (j['speakers'][c] == players[1]):    \n",
    "             message += 'B:' + j['messages'][c] + token\n",
    "                \n",
    "    conversations.append(message)\n",
    "\n",
    "df1 = pd.DataFrame({'conversation': conversations, 'A_bad_intent': 1 , 'B_bad_intent': 1})                     \n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd523135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]A:Germany!\\n\\nJust the person I want to speak with. I have a somewhat crazy idea that I’ve always wanted to try with I/G, but I’ve never actually convinced the other guy to try it. And, what’s worse, it might make you suspicious of me. \\n\\nSo...do I suggest it?\\n\\nI’m thinking that this is a low stakes game, not a tournament or anything, and an interesting and unusual move set might make it more fun? That’s my hope anyway.\\n\\nWhat is your appetite like for unusual and crazy?[SEP]B:You\\'ve whet my appetite, Italy. What\\'s the suggestion?[SEP]A:👍[SEP]B:It seems like there are a lot of ways that could go wrong...I don\\'t see why France would see you approaching/taking Munich--while I do nothing about it--and not immediately feel skittish[SEP]A:Yeah, I can’t say I’ve tried it and it works, cause I’ve never tried it or seen it. But how I think it would work is (a) my Spring move looks like an attack on Austria, so it would not be surprising if you did not cover Munich. Then (b) you build two armies, which looks like we’re really at war and you’re going to eject me. Then we launch the attack in Spring. So there is really no part of this that would raise alarm bells with France.\\n\\nAll that said, I’ve literally never done it before, and it does involve risk for you, so I’m not offended or concerned if it’s just not for you. I’m happy to play more conventionally too. Up to you.[SEP]A:I am just sensing that you don’t like this idea, so shall we talk about something else? That was just a crazy idea I’ve always wanted to try. I’m happy to play more conservatively.[SEP]A:Any thoughts?[SEP]B:Sorry Italy I\\'ve been away doing, um, German things. Brewing Lagers?[SEP]B:I don\\'t think I\\'m ready to go for that idea, however I\\'d be down for some good ol\\'-fashioned Austria-kicking?[SEP]A:I am pretty conflicted about whether to guess that you were telling the truth or lying about the “brewing lagers” thing. I am going to take it literally and say 👎 even though I don’t think you meant it deceptively. 😉[SEP]A:But I think I can get over “Lagergate” and we can still be friends. \\n\\nAs of right now, I think Austria may be my most reliable ally. I’m thinking I’d like to play as a Central Trio if you have any interest in that. Thoughts?[SEP]B:We haven\\'t even passed a season yet and you have a \\'most reliable ally\\'?\\n\\nI\\'ll consider this proposal but, basically, I\\'m not going to expose myself to risk from either of you until I\\'ve seen a bit of your behavior[SEP]A:Well, at least I have an idea of who to trust. Obviously, my ideas are subject to change. \\n\\nI understand your desire to watch behavior before committing to anything. I, personally, am a partner player. I look carefully early in the game for a small group to work with, and then I value loyalty and collaboration. I like to work closely with a tight-knit alliance. \\n\\nIf you prefer to hop and back and forth, or play more of an individual game, then we might not be a good match. \\n\\nI’m looking for a loyal ally or two that I can coordinate with and make awesome moves with. Makes the game easier and a lot more fun.[SEP]A:Just an FYI: I’ve now had both England and France suggest to me that I should move to Tyrolia and France will support me to Munich in the Fall. One saying that to me is not a big deal, but with both mentioning it, my alarm bells are going off. I am concerned about an E/F. \\n\\nI’m certainly not moving to Tyrolia. But I just want you to be cautious here. I feel like England and France are working together.[SEP]B:I appreciate the tip, but I\\'m wondering why you\\'re so against ousting me from Munich if I haven\\'t explicitly agreed to be your ally?[SEP]A:Because it is terrible, terrible play for Italy to attack Germany, in my view. If I were to attack you in Munich, I could never hold Munich. So, all I would be doing is weakening you, and helping France, England, or both to get really big. \\n\\nI don’t have any long-term path going north. Helping France to take you down is a sucker’s play, whether you are working with me or not.[SEP]A:Did France tell you he was moving to Burgundy, or was that a stab?[SEP]B:I was not informed of it, no. And England is leading me to believe it\\'s part of a play for Belgium, so if they\\'re working together this might be a trick...\\n\\nItaly, you seem like a straight shooter, and Austria has confirmed with me about your two\\'s alliance. So I\\'ll confide in you--this is my first ever game of diplomacy, and I think that teaming up with the two of you could help me learn more and have more fun. So, if you\\'re still interested in a central powers alliance, I\\'m in.[SEP]B:Okay full disclosure: I\\'m not very smart, and I accidentally let slip to England that you told me France was plotting to take Munich. I\\'m sorry for the error but I figured it was better to admit it so you know that England/France may not trust you.[SEP]A:Okay, thanks for telling me.[SEP]B:So, um, no alliance then?[SEP]A:I do want to be allies. Sorry, busy weekend here running around with bambinos. More to come.[SEP]B:What would you think of helping me take Marseilles in two turns?[SEP]A:Hi Germany, I’ll certainly consider that. Though, I’ll note: traditionally, Germany would help Italy to Marseilles if the two of them work together there. The reason is that: if I help you to Marseilles, I’m basically cut off from going west and getting anything myself. So, usually, Germany would help Italy into Marseilles to encourage Italy to come west and Germany would plan to take Paris, Belgium and Brest.[SEP]B:Fair enough--I\\'ll help you take it, then, but I\\'ll need to deal with Belgium first.[SEP]A:How are things going with England? I think that getting him to work with you is the main key here.[SEP]B:I\\'m trying--I just offered to assist with taking Sweden in exchange for some assistance into Belgium...not sure if they\\'ll go for it...[SEP]A:I’ll check with England and try to see where his head is at.[SEP]B:I\\'ve actually been thinking about this game all day 😅  and have come up with a plan I like a bit better... but England still hasn\\'t responded to my initial offer.[SEP]A:That’s the worst!\\n\\nAnd I’m glad to see you’re so focused on this in your first game. It’s a really great game if you put in the time and effort![SEP]B:You\\'re definitely telling the truth on that one. So can I count on you to move to piedmont this season?[SEP]A:I don’t think I can afford to move to Piedmont this season. I don’t really trust Austria to avoid walking through that door if I leave it wide open. \\n\\nI think you need to get England on board to attack France.[SEP]B:That\\'s valid. And actually I was conferring with England and we concluded that it\\'s not really gonna be possible for me to help you take Marseilles this year anyway. \\n\\n...what are you and Austria planning for this year, then? I\\'m willing to tell you my plans in exchange as a gesture of trust. \\n\\nHave you communicated at all with England or France?[SEP]A:Hi, are you there?\\n\\nJust woke up. \\n\\nEngland did return my message, but he did not tell me anything substantive so I really don’t know what he’s doing. I’m planning to move towards Turkey.[SEP]A:Well, you’re in trouble. That England move is trouble. \\n\\nI’m going to try to convince him to change course. I suggest you be very kind to him, and don’t burn that bridge. I think your game hinges on turning England around.[SEP]A:Hi Germany,\\n\\nI’m working hard on turning England. And I’m also trying to get Russia to come to your aid. Doing the best I can! I’ll keep you posted.[SEP]B:England just told me that Russia is helping them to take Denmark so that may be a lost cause. Granted, the source for that intel is a serpentine jackal-spawn[SEP]A:Okay, I’m reasonably sure that England wants to take the Channel and attack France now. \\n\\nI believe that you should basically do whatever England asks to help make this happen. As long as E attacks F, you will be in a much better position, and you’ll gain back centers quickly. \\n\\nWhat are you hearing?[SEP]B:What are your plans for this turn? I can\\'t help but notice that Munich is surrounded by foreign armies on three sides...\\n\\nI wish I could be more helpful but I\\'m pretty much just treading water right now trying not to lose anything else[SEP]A:Hey — sorry, just getting back into this now.[SEP]A:I have good news! (1) I am finally attacking France this turn. (2) I will be supporting Munich to hold from Tyrolia. \\n\\nLet’s turn this game around, yes?[SEP]A:I am pretty sure that England is not attacking you this turn. And I am committed to supporting Munich holding. Make sure you don’t move Munich so that it can take my support.[SEP]B:Okay, can do. Thanks![SEP]A:I suggest that you order:\\nKiel Support Berlin holding\\nBerlin Support Munich holding\\nHelg to Holland\\nMunich Support Berlin holding[SEP]B:I agree completely--although I didn\\'t know that a country could hold *and* support at the same time! Thanks![SEP]B:Thanks Italy. Hope you\\'re enjoying the weather on the Anatolian 😉[SEP]A:I will be supporting Munich to hold again. And I’ll be trying to get Russia to back off your flank and protect himself against an Austrian stab that is coming.[SEP]A:Two bits of advice: #1 I suggest you tell Russia that Austria is coming for him. You really want Russia to move Sil back to Gal. You might also suggest to Russia that is he supports you to Denmark, you will then support Russia back to Sweden. I don’t know yet if it actually makes sense to do that, but you want Russia thinking that you are eager to work with him. He’ll be hoping for a reason to break off his attack on you at this point.[SEP]A:#2 Here is the move set I would suggest right now:\\nKiel Support Holland holding\\nHolland Support Wales to Belgium (tell England you are going to order this support and he can take it or leave it)\\nMunich Support Berlin holding\\nBerlin Support Munich holding\\n\\nI think that both France and Russia are about to back off you, as they are both under fire at home. Just hold still, and soon you should be able to break out of this holding pattern.[SEP]B:God, I hope so! I\\'m attempting to make that deal with russia now...and I\\'m talking with England re: Belgium[SEP]A:It’s none of my business, but if you do plan to take Denmark, I strongly recommend you wait until Fall. I think the most important thing for you right now is getting England fully committed against France. If that happens, taking Denmark later will be easy.[SEP]B:I think me and England are really on the same page at this point regarding France. I\\'m actually sort of running counter-intelligence for England (and my friends to the south, of course!) with Russia right now. \\n\\nEngland and I talked about Denmark too...and it seems like one or the other of Denmark or Belgium should work out for me this year and I\\'m fine with that[SEP]A:Great to hear. Thank you.[SEP]B:Do you need me to disrupt Bur this year? I\\'ll need to seriously trust Russia if I\\'m going to risk not holding my eastern front, I think...[SEP]A:I do think a move to Burgundy makes sense for you this turn, and I can’t imagine Russia attacking you here. He has a serious Austria problem. \\n\\nI suggest this:\\nMun - Bur\\nRuh - Bel\\nHol Support Ruh - Bel \\nBer - Kie\\n\\nTell Russia that the last thing in the world you want to see is Austria run him over, and you’re willing to help keep Russia viable if necessary (you’re angling for Russia to disband his northern holdings this turn).[SEP]A:And ask England nicely to support Ruh - Hol, with the explanation that you don’t plan to ask for Denmark back, but you think it would help you both to diminish France. (You’ll get Den back eventually, but you want England to think you don’t care about it).[SEP]B:Thanks, I\\'ll work on these. \\n...Why didn\\'t you scooch into the Aegean behind Austria? You could have defended or even held Bulgaria this turn?[SEP]B:England and I were talking about your moves for this season--what do you think of convoying Pie into Spa, supporting this with Wes, and then moving Tyr into Pie?[SEP]B:This leaves Marseilles open for Bur to fall into if France goes that route, which gives me an opening into Bur[SEP]A:That’s not bad.[SEP]A:I was kind of thinking I should pick one or the other of Marseilles or Spain to attack and not tell a soul which one I’m going after.[SEP]A:Do you really think it’s important to coordinate?[SEP]A:I do think you’re best off moving to Burgundy. And there is some chance that we fail this turn. But I think we just take a guess and hope for the best. We’ll get him next turn if not this one.[SEP]B:Okay—sorry for being nosy! I will try for bur on the off chance it shakes out that way[SEP]A:Nah, you’re not being nosy at all. I mean, come on, we both know that I have no problem sticking my nose where it doesn’t belong.[SEP]B:Marked as true[SEP]A:I like to coordinate, but on these sort of 50/50 guesses, I kind of like to keep it secret so that if it doesn’t go well, I have nobody to blame but myself.[SEP]A:Ha![SEP]B:Well, are you willing to humor my question about the Aegean, anyway?[SEP]A:Sure. I was thinking of moving that fleet to Ionian. You think a move to Aegean is better? I’m not really sure, but let’s talk it through.[SEP]B:No sorry I meant in hindsight--like this past turn you should have moved to Aeg so that this current turn, when Austria takes Rumania (from Bulgaria), you\\'d be there to cover Bulgaria so it couldn\\'t get scooped by the Black sea, and potentially you\\'d just get to take it.[SEP]A:Not a bad point. I agree.[SEP]A:Hmmmm, kind of a pointless lie if you ask me, but I won’t hold it against you. You’re in a tough spot.[SEP]B:um what lie? I did exactly the moves you suggested![SEP]A:Ha! So sorry!! I meant that for France![SEP]A:You are my favorite.[SEP]B:Marked as lie because clearly austria is your favorite.\\nSpeaking of, I assume that your seizing Trieste was mutually agreed upon?[SEP]A:Yes — agreed upon.[SEP]B:That\\'s not what Austria said to England...[SEP]A:Hmmmm, okay. Well, let’s just keep that between you and me then. 🤦\\u200d♂️[SEP]B:You know italy, I think we *do* need to coordinate your move this time--England and I have a shot at either Bur or Mao if one of Marseilles or Spain can be left open for France to fall into. This will improve all of our chances of crushing France quickly.[SEP]A:Okay, I can dig it. What do you want me to do?[SEP]B:Let me confer with England and get back to you. Glad to hear that though![SEP]A:So...any thoughts on how to approach this?[SEP]B:It looks like England\\'s not willing to try for MAO if it means possibly losing the channel. However, they\\'ll bring the NWG fleet around to try for MAO next year. \\nSo if you could keep Marseilles open, it will help me to try and take Burgundy this turn.[SEP]A:If I leave Marseilles open, would you kindly use Burgundy in the Fall to help me take Marseilles? (Likely that means ordering Burgundy to Gascony to cut support)[SEP]B:Will do.[SEP]B:Okay, so I still have a teensy little bone to pick with you: on the off-chance that Austria wasn\\'t lying and you *did* take Trieste unexpectedly, I sort of worry that I might be next. Are you willing to tell me what your plans are for the Tri unit, or at least to warn me before any move into Tyrolia?[SEP]A:Sure. But, you’ll see from my moves this turn that Austria is lying to you.[SEP]A:I currently have Tri - Tyrolia. I like the unit there because it sets up an attack on Austria if I ever want to go that route (build A Ven and go east). Do you want me to keep Tyrolia clear?[SEP]A:I’ll add — I would never attack Germany as Italy. Setting myself as a giant column like that is just not defensible. It would be a terrible move.[SEP]B:Not when that column is not-so-giant and in a turf war with France.[SEP]B:oh you mean setting *yourself*[SEP]B:But you could easily pick off, say, Munich and not be a \"giant column\"[SEP]A:I mean this sincerely: any Germany who does that is a terrible player. \\n\\nWhy would I do that? I would need 2-3 units to hold one center. That is a net negative. And all of your units are doing things that are good for me in containing your neighbors. \\n\\nI’ve been working hard in this game for you to succeed and knock back France and England. I can say with 100% certainty: I’m not going to attack you. I’m going to keep helping you as much as I can.[SEP]A:That said, if you want me NOT to move to Tyrolia, I won’t move there.[SEP]B:Nah, I just needed some reassurance :)\\nYour logic is undenyable— enjoy your stay in tyr![SEP]B:*undeniable? That looks better[SEP]A:I mean it sincerely. I think that England will want to coax me to attack you with him after France falls, but I’d much rather work with you against England. \\n\\nBut first thing’s first — let’s get rid of France.[SEP]B:Agreed[SEP]B:(On the france part)[SEP]B:Sorry I won\\'t be able to cut off Gascony this turn...I probably should have just told you my moves; you could have advised me that supporting Mun-Bur was more important than Kie-Ruh[SEP]A:No worries. We’ll crack this but eventually. \\n\\nHere is my suggestion for this turn:\\nKie - Den\\nHol S Bel holding\\nBel S Ruh - Bur\\nMun S Ruh - Bur\\nRuh - Bur[SEP]A:I think you should suggest to England that he gets Sweden and St Petersburg, while you get Denmark back. That’s only fair, as you have been a loyal ally in the fight against France and you plan to continue to do that.[SEP]B:The moves I had already planned differ in one respect: I thought it would be worth the risk to try moving Hol-Bel and therefore move Bel-Bur. Even if me and France are high-fiving in Bel for a few seasons it\\'s still mine, and it\\'s not like Holland has anything better to do while I\\'m still allies with England.\\n\\n...The only reason I\\'m reluctant to make that agreement with England is that---while I think *you* and I have a good relationship---I really have not talked with Austria much at all, and I\\'m the next logical target for them when Russia\\'s gone. And anything that\\'s bad for Russia right now is good for Austria.[SEP]A:Hmmmm, I’m just not sure you should trust England enough right now to leave Holland open and Belgium essentially unguarded. \\n\\nFrance is a really good player, and he is no doubt working hard to get England to turn on you. My personal take is that you are better off being a bit more conservative until you have Denmark back and England has moved another fleet towards France. But I can see it either way.[SEP]A:With regard to Russia, talk it through with England. What you don’t want is England taking out Russia and giving you nothing. So, if England agrees to let Russia be for a while, then your plan sounds good. But if England is going to take Sweden, you really should get Denmark back. (I’m my view)[SEP]B:Okay you\\'ve convinced me: it\\'s worth figuring out what E\\'s plans are for Russia at least.\\n\\nAnd you\\'re almost certainly right, from a rational perspective, about leaving Holland/Belgium vulnerable to England. But I think England really is counting on my assistance in taking France, and because of that and other non-quantifiable reasons I trust them.[SEP]A:Excellent. Obviously you have a much better feel for your relationship with England than I do. Just know that France is persuasive, and I’m sure that’s what he’s working on. He stopped talking to me, so I bet he’s trying to turn England. Just keep reassuring England that you want to work with him long-term so he doesn’t succumb to the Dark Side.[SEP]A:Hi Germany — well, I think we’re getting to a critical point in the game here. France held out a long time, but he’s much less of a threat now. I think the critical issue, for you, is England. \\n\\nI have some thoughts on the matter, and some information, but I’d like to feel confident that you and I will keep anything we say between us. I think of you as the one person who has been honest with me on every turn. You even tell me the truth when it’s bad news, or when you don’t completely trust me, and I like that.[SEP]B:Okay, Italy. I won\\'t share any of this conversation. But in the interest of continued full disclosure, here\\'s what I think: England is a greater threat to *me* on the map, but *you* have a greater chance of soloing this game quickly, or pair-winning with Austria even sooner. And if I continue to collaborate with England, we at least have a chance of slowing that down. So I\\'m in sort of a conflicted spot[SEP]A:This is why I like you. The full disclosure part. You tell me the truth even when the news isn’t great.[SEP]A:My thoughts on the “Germany/England forever so that at least we can stop the solo” strategy: (1) It’s quite early to be talking about solos. I am at 8, and Austria could take 3 from me any time, quite easily. (2) I don’t think England is thinking that way. I think he’s thinking that a dominant power will emerge in the north, and one will emerge in the south. And he’s like to be that dominant power.[SEP]A:England’s pieces are not positioned well if he’s trying to attack France or contain Italy. He keeps Denmark guarded, and North Sea filled. He is not playing like he intends to stick with you, even though I’m sure he’s telling you that.[SEP]A:You’re right that you don’t want to start a war with England right now. But, you must stick up for yourself, because nobody else will do that if you don’t.[SEP]A:If I were you, this is what I would do: (1) keep warning England about the dangers of Italy getting too big and insist that England moves his fleets towards MAO (Channel to Irish, Norwegian to NAO, North - Channel), (2) insist on taking Denmark back.[SEP]A:I would say something like this:\\n\\nEngland, I’m with you my friend, but we’re passed the stage of you needing to keep me under lock and key. I need to take Denmark back. I’m happy to support you to Brest to keep you growing, or you can grab Sweden. You have plenty of options other than keeping your ally’s center, but if you really want to be my ally long-term, you’ve got to show me that.[SEP]A:I am hearing from England signs that he may be thinking of attacking you soon. And I think you actually avoid that better by being strong and sticking up for yourself rather than being accommodating and letting him do whatever he wants to do.[SEP]B:Well, both you and France have now pointed out that England is strategically not in a good place to be my ally right now, and you are correct. I\\'ll be more cautious with my northern border, but I made a pretty strong argument for denmark this past turn and it fell on deaf ears[SEP]B:...which probably also should have been a sign for me[SEP]A:Well, if you want, you could just take Denmark this next year and I don’t think England is in a position to retaliate.[SEP]B:Probably not...has France been talking with you at all about their sunsetting strategy? They\\'ve indicated a willingness to work with you and me and a desire to see England get as few dots as possible[SEP]A:He did say that to me too. Though, France has a long history of lying to me, so I really don’t trust him.[SEP]B:Well France has actually been pretty honest with me, and I at least am certain that they wouldn\\'t betray me to England. So, I\\'m considering working with F to sabotage (or potentially full-on backstab) England this turn, which would have the side-effect of maybe taking some attention away from the south for you anyway.[SEP]B:(and I\\'d be interested to hear your thoughts on this if you\\'re in the mood to give out free advice)[SEP]A:Hi Germany — sorry for the delay. Well...I think it’s really important that you get a build this turn either way. I don’t think England will get a build this turn, so if I were you I’d probably take Paris, build a fleet, and move on England after that.[SEP]A:But it likely depends on how communication is going with England. If he’ll give you back Denmark, that might change the equation.[SEP]B:I am waiting on England to make a decision about that--they claim to be thinking about it.[SEP]B:England told me you said I was plotting with France. It makes sense you’d want to pit us against each other.[SEP]A:Hey — tried to send you a message earlier but not was down. England was telling me that you’re saying that I told you that England is plotting against you. The problem with telling England that is that he will stop giving me useful info.[SEP]A:Truly, I don’t want you and England to fight. I am not trying to break you up. I suggested that you take Paris! I want you guys to work together with me against France.[SEP]B:You don\\'t want us to fight, yet you betrayed both of our confidence with you in a way that makes us distrust each other?[SEP]A:I really don’t think that’s a fair description. You guys both wanted to attack each other. I encouraged you both to keep working together.[SEP]B:Just as long as it suits you. Are you going to give England Mao?[SEP]A:Hmmm, should I be reading that as angry sarcastic with dagger eyes? (I’m not sure if I’m getting your tone right)[SEP]A:We’re friends, right? I believe that every single message I’ve sent you all game has been truth, and I’ve gone out of my way to give you candid advice. Are we still friends?[SEP]A:Regarding MAO — I don’t know. What do you want me to do? I don’t have any set plan.[SEP]B:Yep, there\\'s some sarcasm there. Looking back at your messages, I still don\\'t read them as encouraging collaboration. And if you wanted us to be friends, you could have done that without betraying me to England by simply saying in your candid way \"I don\\'t think you should do that for such and such reason\". But you chose to increase E\\'s distrust of me. So I think you might be full of gnocchi and crap. \\n\\nMy trust in you is a bit shaken but I still think we can have a working partnership with a bit more caution on my end. It would be my preference that you hold Mao, on the assumption that if it came down to a choice between partnering with me or England, you\\'d choose me. If that\\'s not the case, then as the filling of an England-Italy sandwich I\\'m in no position to retaliate anyway.[SEP]A:Well, again, I like that you’re honest with me, even when the news is bad.[SEP]A:I have to say that I’m surprised that you feel that I’ve betrayed your trust. I have been feeling like maybe I’ve been TOO helpful to you, and been a bit over the top in offering advice, etc., but it seems like I’ve misread the situation.[SEP]B:No, it\\'s completely true that you\\'ve been too helpful, and I\\'m really really grateful for it because I\\'ve been able to learn so much from this game. But it\\'s also true that you didn\\'t have to tell England what you did, and all you stood to gain from it was that it shook my and E\\'s trust in each other.[SEP]A:But I understand what you’re saying, and I much prefer to have a heart to heart like this, a frank airing of grievances, rather than being surprised by unkind moves on the board. https://youtu.be/xoirV6BbjOg[SEP]B:Was not expecting seinfeld today and it was a pleasant surprise[SEP]A:🤗[SEP]A:Here’s the deal: I like you better than England.[SEP]A:I’m not sure how the next couple of turns are going to shake out. But I like that you tell me when you’re angry with me. I know that may seem like a small thing, but it’s just rare in Diplomacy. You get so many fake smiles.[SEP]A:So, if it comes down to you or him, I’m choosing you. And I’ll work to do a better job of keeping your confidence. I certainly understand how important that is, as I hate it when people o that same thing to me.[SEP]A:So no more playing mediator for me.[SEP]B:Okay. Is it true that you want the channel?[SEP]B:And are you planning to keep Vienna?[SEP]A:I am not planning to keep Vienna. And yeah I’ve asked France for support to the Channel. Do you think he’s on board?[SEP]B:I\\'m not sure. Is *England* on board? Is this something England can know about?[SEP]A:No, do you think France will Support me to the Channel?[SEP]B:France has asked my opinion on it, and I haven\\'t given it yet. To my estimation things look a lot better for me if you don\\'t end up there: I don\\'t want to see England in Mao, and I don\\'t want to see you snagging pieces of the north.[SEP]A:Okay, well, here is my thinking. Tell France whatever you want to make him happy. Then tell me how you really feel. And if you don’t want me to go there, I won’t go there.[SEP]B:If I hadn\\'t asked you about it, would that have just been another surprise, too?[SEP]A:Absolutely. \\n\\nYou and I have discussed our moves and been honest with each other every turn. But we have not been sharing all our moves or pre-clearing all of our moves. So that would have Ben a surprise in the same way that your moves are a surprise to me. (I never tell you what to do or insist on knowing).[SEP]A:I kind of thought that you would have wanted me in the Channel because it commits me further against England, but I can understand what you’re saying now about wanting me to hang back.[SEP]A:But I don’t think there is anything wrong with me contemplating moves without telling you all of them. You asked me about it, and I told you the truth.[SEP]B:I do think that this move is a breach of general expectation, which is the kind of thing I\\'d like to know about. And it\\'s also the kind of thing I\\'ve shared with you: case in point, my desire to stab England.[SEP]A:Okay. Understood.[SEP]B:Is there anything I could gain from seeing you in the channel? Would you support me taking Nth, and potentially seizing the island?[SEP]B:Here\\'s what I\\'m thinking: I would be on board with you taking the channel (and I\\'d give France the green light to go ahead with it) if you would agree to bump Nao out of Mao using Wes, and if you\\'d be open to supporting some anti-English aggression while holding the channel so that I can get on equal footing with you, dot-wise.\\n\\nIf you don\\'t want to agree to those terms, that\\'s okay, but I would strongly prefer not to see you in the channel in that case.[SEP]A:I’m going to be out of pocket this weekend, so let’s talk this through more on Monday. Generally, I agree that I’ll either stay out of the Channel or agree to your terms for entering there.[SEP]B:If you decide to stay out of the channel, I have a deal that I like with England in the works. For that deal to go through, you\\'d have to agree to move Mao into Portugal to let England take Mao. Would you be amenable to that?[SEP]B:(If this second offer is more to think about than a no-brainer, you can just mull it over and let me know monday)[SEP]A:So, here is my concern with the England offer: If I’m taking Portugal, why do we want England in MAO? And why would he want to go to MAO? I’m not sure I understand that one. Can you explain?[SEP]B:Well, when I initially proposed the deal I had forgotten that Portugal was promised to England. Then England agreed to it on the condition that you would confirm that move, so I figured E thought you would just move out of there next year? But now that I think about it, it’s probably worth asking England why they’d agree to that.[SEP]A:I’d prefer that you not tell England I am considering moving to the Channel. I don’t think he would like that.[SEP]A:I don’t really want to discuss this stuff with England at all.[SEP]B:Well, England changed their mind about the plan I offered anyway. So, are you taking the channel?[SEP]A:No, I’m not taking the Channel.[SEP]B:Okay was that a recent decision? Because like an hour ago France said they were supporting you into the channel[SEP]A:Well, when I tell you what I plan to do, do you turn around and tell France? This makes me uncomfortable speaking with you.[SEP]B:I haven\\'t spoken to France since then. I didn\\'t realize you were giving the two of us different information on this particular subject. But I don\\'t think I\\'ve revealed anything to them about what you plan to do. Mostly because you haven\\'t told me.[SEP]A:Well, I have been honest with both you and France. You told me that I need to promise you a set of things in order to take the Channel. I felt like it was more than I could be sure of doing, so I am not entering the Channel. I won’t go there without your permission.[SEP]B:I appreciate that. And I\\'ll keep the remainder of this conversation between us unless I hear otherwise. Have you just recently made an agreement with England?[SEP]B:I heard as much but I want to verify the contents of that agreement with you[SEP]B:Btw, France just said that they submitted the orders to support you into the channel.[SEP]A:I don’t have an agreement with England, but he is asking me about my moves and trying to get my help.[SEP]B:Okay--then England is lying to me, saying that you\\'re helping support Eng-Brest.[SEP]A:Ha! Yeah, fat chance.[SEP]B:...but did you lie to England about that? Or can I say to England that I don\\'t think you\\'ll actually provide that support?[SEP]A:What is Paris up to?[SEP]A:I suggest you just not tell England anything about my moves.[SEP]A:Do you want me to support England to Brest?[SEP]A:I guess I’m not sure what your goals are here.[SEP]A:I just kind of feel like you’re grilling me with a lot of questions, but not telling me what you’re doing or what you want from me.[SEP]B:*If* you support Eng-Brest, England has agreed to vacate denmark for me. If you don\\'t, I won\\'t get in the way of your channel thing. Any other questions?[SEP]B:I have no sense of what you want or what your plan is, but I thought I\\'d been pretty clear: I want Denmark. I am reluctant to see you in the Channel if England remains powerful, but happy to see you there if they are weakened.[SEP]A:Can’t you just force Denmark?[SEP]B:Not without risking a swipe of Belgium[SEP]B:And why force when you don\\'t have to[SEP]A:Okay, I’ll support England to Brest. You take Denmark.[SEP]A:And you and I should be in position to take out England next year.[SEP]B:Splendid![SEP]B:Glad everything worked out 😃[SEP]A:👍[SEP]A:Congratulations on retaking Denmark and getting two builds. You are playing really well right now. Respect.[SEP]B:Congrats on having double-digit dots! I have some thoughts about taking out England, if you want to go full-stab this season...[SEP]A:I think I do! 🤫[SEP]A:What are you thinking?[SEP]B:One option is to take the channel, another is to take Brest. Between you, me, and Picardy we can manage either, but it\\'s a question of which takes priority. If we chose Brest, I could also take a stab at seizing Nth this season, then we could try for the channel in fall. Or we could do channel first, Brest second.[SEP]A:Yeah, that is all along the lines of what I’m thinking. How demanding does France sound right now? Does he want to be the one who takes Brest?[SEP]B:Haven\\'t asked. But in general not demanding.[SEP]A:Good!\\n\\nStill, I think we should show him some good faith by supporting him to Brest in Spring. We can decide in Fall whether it makes more sense for you to take it, but I think we want to keep France hungry.[SEP]A:I would suggest something like this to ensure the English fleet is disbanded:\\nPic - Bre\\nMAO - Channel\\nPar S Pic - Bre[SEP]A:And Spa - Gas to cut off that retreat.[SEP]A:You can take the North Sea on the same move and set up a convoy to the English mainland. \\n\\nCheckmate.[SEP]B:Okay, I like the plan! I\\'ve asked France if they\\'re willing to move to Brest supported by me.[SEP]B:Aren\\'t you concerned about England taking Mao? I\\'d sooner just have you pile on support into Bre so that Wes can support Mao holding[SEP]A:That’s a good point, but the problem with that approach is that Brest is not guaranteed. If England cute MAO and supports with the Channel, the attack fails. I think we are better off ensuring that the Brest fleet is disbanded. If we disband that fleet and take North Sea, an English fleet in MAO really just spreads him out and allows you to take the island faster. It’s not like he can get Portugal or Spain.[SEP]B:Okay, but that means I\\'d prefer to take Brest myself this Spring, if France is okay with it.[SEP]A:I think that we should offer France Brest in Spring. That ensures that he is with us. Then, if conditions are right in the Fall, I can support you into Brest. But...England can offer France Belgium, and I think he is sure to take that if we’re not even offering him a center, right?[SEP]A:Better to keep France feeling like we’re going to keep him in the game. If you need the build in Fall, it’s easy for me to support you there.[SEP]B:I guess I’m just wondering from France’s perspective why they’d *want* to stay in the game. Isn’t it possible they’d rather move on with their life? That’s not rhetorical, I’m wondering what your perspective is as a veteran player[SEP]A:Here is my take: If France just wanted to go down in a blaze of glory and say “eff you” to England, he would have kept Irish Sea. He kept Pic, which is next to his home center, and gives him a chance to negotiate with both you and England.[SEP]A:I think that means he is motivated to keep trying. And if he believes he can get Brest, he could legitimately get back to his feet. I know that’s what I’d be trying to do in his position.[SEP]A:As the poker saying goes: “a chip and a chair.” So long as you have one chip left, and you’re still in the tournament, you can always come back to win.[SEP]A:Thoughts?[SEP]B:I think that makes sense. Are you talking with England at all?[SEP]A:I’m pretty wary of England right now. He asked me what I want to do, but I feel like he’s trying to get me to leave MAO open. That’s not terrible news, as it suggests that he won’t expect your move to North Sea.[SEP]A:As long as he doesn’t move NAO to Norwegian, you’ve got a guaranteed supply center.[SEP]B:Well E\\'d have to be a right dolt not to retreat to NWG. And right now they\\'re talking to me about supporting a move from Bre to Gas (the better for the two of us to stab you).[SEP]B:What i mean is, there\\'s a good chance that Mao is safe if I \"agree\" to that deal[SEP]B:Oh nevermind--they\\'re not going to convoy into Brest. So actually this pretty much guarantees that Eng and Nao will try for Mao.[SEP]A:Ahhhh, sneaky Devil! Thank you for letting me know.[SEP]A:I still like our plan.[SEP]A:I need to run for a bit. I’ll be around in a few hours.[SEP]B:I think that knowing this, you should do as I suggest and not poke Eng. Just hold and let Wes support. I am 94% sure I can trust England to do as they say on this one.[SEP]A:Okay. Should I support Pic to Bre?[SEP]B:yes please. It\\'ll do us good with France too if we both support.[SEP]A:👍[SEP]B:Actually, you should use Mao to support Spa-Gas, since we know that Brest is moving there. It will be beneficial to have you there if we decide to oust France from Bre in fall[SEP]A:Consider it done.[SEP]A:Hmmmm, heading anything from England?[SEP]A:I’d love to talk if you’re there. I’m getting the impression that England may actually be moving on you, and I think I have a good counter, but I also still think we should support the attack on Brest and take North Sea.[SEP]A:I definitely think you should keep your moves the same.[SEP]A:Nice! Get’em! He WAS moving on you. But we should be able to take about 3 off of him now. Very nice turn.[SEP]B:Sorry; I was asleep by 9 last night 😂  \\n\\nwhy the move to Nao? Wouldn\\'t IRI be the more anti-England choice?\\n\\nWith the move to Picardy and assuming a retreat to SKA, it looks like England has me pretty powerless this turn.[SEP]B:So do you, it seems, if you have some kind of deal with Russia about Munich.[SEP]A:Good morning. \\n\\nJust responding to your messages above. I think NAO and Irish are equally anti-English. They both give me a clear lane to attack Liverpool. I wasn’t sure if either one would be left open, but I took a gamble and it paid off.[SEP]A:Re your move this turn, I don’t think you’re powerless. You should get a build I think and if not, you should be in position to smash England.[SEP]A:I don’t have a deal regarding Munich, Germany. Frankly, I thought you would be a bit more joyful towards me. By attacking England, I have committed completely to working as your partner.[SEP]B:I suppose you\\'re right. Initially I was thinking IRI also gives you channel access, but NWG access may be just as useful. \\n\\nWell when you control half a continent (and even more when you consider your influence over me, austria, and who knows who else!), there\\'s no such thing as complete commitment. I\\'m not so naive as to think your allegiance with me is going to last beyond its usefulness, and with two fleets on the British isle that time is fast approaching. To be clear, I\\'m still giving you the truth and I still want to work with you. But you should really stop acting surprised when I\\'m slightly paranoid that a soon-to-be-dozen-dot-holder is gearing up to stab me[SEP]A:Well, I dunno, it sounds like I should stab you. Is that what you’re trying to tell me?\\n\\nI like you. I like how hard you’ve worked in this game to rebound from a difficult start. I like that you e told me the truth, even when the news was bad. I like that you tell me when you don’t trust me. I have literally never told you a lie in this game, and I don’t intend to start now. Last turn I burned my bridge with England beyond repair. If you don’t want to work with me now, that’s really disappointing.[SEP]B:like I said, I *do* want to work with you. However, remember that thing I said about general expectations and being warned when they\\'re broken? Tyrolia is one of them and I think you knew that. And England *also* told me they\\'ve never told me a lie; I\\'m starting to think that\\'s Diplomacy-speak for \"when convenient, I\\'ve used careful wording and half-truths to deceive you even when everything I said was technically true\". \\n\\nIt would help me to know that you see me being a benefit to you beyond taking out England. A natural next move for us would be to take out russia, and in that arena I have a positional advantage over you. Especially if I get two builds this turn, I\\'ll be able to sneak behind the troops in bohemia/galicia and help you break through.[SEP]A:Yes — here is how I expect and hope the game will play out: the two of us finish off England and France, while drifting towards the east a bit. With the builds we get this year, we essentially blitzkrieg the East. I have more units than you, but you have no opposition at all in the north, and can take Scandinavia, War and Mos without any trouble.[SEP]A:I think that, in about two years, you and I will both be on about 14 centers, with the remnants of Russia and Austria between us, and we can decide how we want to resolve it. I’d be happy to agree to a small draw, or to shoot for a 17-17 two-way draw position, whichever you prefer.[SEP]B:Well, I like the sound of all of that. In fact, it sounds ideal: there\\'s something poetic about the complete beginner and the expert (you\\'ve probably heard by now that you got doxxed) sharing a victory. \\n\\nI ask for a concession: As a show of good will, would you be willing to take only one of Liverpool or Portugal this year? (I know the Portugal request seems weird, but I like keeping France around and unless I\\'m mistaken they like me better than you 😃 )[SEP]A:Yes. I wasn’t planning to take Portugal anyway.[SEP]A:I think it makes sense here for you to land an army in the English island while you can. Now that his army is off the island, he’s toast as soon as you do that.[SEP]B:England\\'s just vindictive enough to try and stab Belgium with England and Picardy, though. I was planning on keeping holland around as support.[SEP]B:*by England I of course mean Eng[SEP]A:I suggest the following:\\n\\nGas - Liv (via convoy)\\nSpa S MAO holding\\nMar hold\\nTyr - Tri\\n\\nHol - Yor (via convoy)\\nBur S Bel\\nBel S North\\nHEL S North\\nMun - Boh\\nPar - Pic (to cut any potential support)[SEP]A:England cannot take Belgium with those moves.[SEP]A:Or I could move my fleet into Liverpool and use Gas to support Bre. I’m happy either way.[SEP]B:I tried a double convoy in the sandbox once and it didn\\'t work! What is this witchcraft?!?[SEP]B:At any rate, I prefer the fleet move to liverpool and Gascony\\'s support into Brest. And could Mao support Bre into the Channel? No sense forcing France to disband. Bel will support it, too.[SEP]A:Here are the orders needed to do a convoy!\\nHolland move to Yorkshire\\nNorth Sea convoy Holland to Yorkshire\\n\\nIt is not a “double convoy” as you only need one fleet to make it happen. \\n\\nBut if your fleet in North Sea is dislodged, the convoy will not go through. That is why I would suggest that HELG supports North Sea holding and Belgium supports North Sea holding.[SEP]B:No--I mean the one *you* were planning: Gascony to Liverpool[SEP]B:It\\'s a double convoy because you\\'re convoying through Mao *and* Nao[SEP]A:Ah, the orders there would be:\\nGascony - Liv\\nMAO Convoy Gas - Liv\\nNAO Convoy Gas - Liv[SEP]A:So, I’ll move the fleet to Liverpool. And you want MAO to support Paris to Brest?[SEP]A:Or wait, MAO supports Brest to Channel, and Gas supports Paris - Brest, right?[SEP]B:yeah. I tried that once in the sandbox (or the equivalent: back when you had fleets in Lyo and Wes I tried  a convoy from Pie to Naf). But I think I messed up the commands to the fleets. \\n\\n And yes the most recent message is correct. Those two things and Nao-Lvp[SEP]A:Okay, confirmed. \\n\\nSo I’ve got in:\\nNAO - Liv\\nMAO S Bre - Channel\\nGas S Par - Bre\\nSpa - WES\\nMar S Gas holding \\nTyrolia - Trieste\\n\\nSound right?[SEP]B:It does. But If Tyr was bound for trieste anyway, why did you detour through Tyr at all? Why not just move to trieste last turn??[SEP]A:Austria would not have liked it.[SEP]A:And he doesn’t know that it’s headed back there now (please don’t tell)[SEP]B:Understood. Me and Austria don\\'t talk anyway. Also, do you have any sense of what England is planning to do?[SEP]A:Ha! No I don’t. I’d imagine he is coming for me. But I don’t know that.[SEP]A:If I were him, I’d defend Edi and London.[SEP]B:So you haven\\'t been talking to England at all? I was sort of hoping you would know more, maybe help us take better advantage of their plans.[SEP]B:Anyway, my moves are:\\n\\nPar-Bre\\nBel s Bre-Eng\\nHol s Bel holding\\n\\nAnd the rest within expected parameters. Correct?[SEP]A:England has not said anything of substance to me. He was gracious about my move, but he won’t trust me again, and I would not trust anything he might say at this point. I haven’t asked him about his moves and he hasn’t told me.[SEP]A:I thought you would Convoy Holland to Yorkshire and support Belgium from Burgundy. Also, can you please order Mun to Boh to cut support and allow me to hold Vienna while moving Tyrolia to Trieste?[SEP]B:I *told* you I\\'m not risking that convoy *and* that instead Bel is supporting France into the Channel (which will heretofore be called the French Channel). And could I persuade you to move to IRI instead of taking Liverpool in exchange for the requested cut?[SEP]A:Sorry, what is the requested cut? I understand that you don’t want me to take Liverpool or Portugal. What are you offering to me? (I don’t mean to be difficult, I just want to be sure I understand).[SEP]A:Ah, you must mean Munich to Boh.[SEP]A:Asking me to avoid taking Por and Liv is asking a lot. I want France to survive here, but I also want England taking units off the board, and I feel like you should too, right?[SEP]B:I do. But I also want those dots for myself, of course. And there\\'s still the nonzero chance that you\\'ve arranged with Boh to take Munich for yourself, so I\\'m taking a serious risk[SEP]A:I will avoid taking Portugal, vacate Tyrolia, and support you to Brest. I feel like I’m offering quite a lot in exchange for one cut support. \\n\\nAnd cutting that support does not put you in greater peril. If I had a deal with Russia for Munich (I don’t) I could cut Burgundy from Marseilles and support Russia to Munich. Moving Mun to Boh to cut support is costless.[SEP]B:You\\'re right. I just thought I\\'d put my best argument forward. I\\'ll do the cut. But I ask for something costless in exchange, and I really, really want it to stay just between us, ok?[SEP]A:Understood and agreed.[SEP]A:And I have no problem with you asking for more than you’re willing to settle for. That’s smart, and I do the same thing sometimes. If you don’t stick up for yourself, nobody else will.[SEP]B:I *know* there\\'s more to your relationship with England than you\\'re telling me. The last message England sent to me hinted that if *I* wasn\\'t willing to work with them--and I haven\\'t said anything to them since--that maybe *you* would. And if England were to reach out to you, you\\'re too smart to just snub them. There\\'s advantage to be gained--either for both of us or just for yourself--from talking to them. The only reason I stopped was because I knew my word would be mud to them anyway.\\n\\nEarlier I was hoping you\\'d give me the truth about what you knew, and about what they might know. But you didn\\'t and that both disappoints and scares me. So I\\'m asking that you give me just a modicum of honesty here: what do you know? what does England know?[SEP]A:I give you my word: I don’t know what England is going to do and I haven’t asked.[SEP]A:He is still jovial with me and respectful. He has asked me to critique his play and to give him advice. But I do not know his moves, and I really don’t think he would tell me them if I asked. It certainly would not be info I could trust free I just lied to him about mine.[SEP]B:But England\\'s desperate. Better to talk with *someone* than just go in blind. And I doubt they\\'d turn to Russia or France because neither is really close enough/powerful enough to give real help. And there\\'s precedent for you negotiating with someone even as you stab them: France.\\n\\n...and here\\'s the real accusation: for all your pretty words about a shared victory between you and me, you\\'ve been sneaky and you\\'ve always pitted me and England against each other to your benefit. My real fear here is that knowing my moves, and with a desperate, jovial England seeking your advice, it would be so *easy* to just feed England enough info to keep me weak while you chow down on the Island. \\n\\nI know this from experience: back when you were doing 50/50 shots in the south of France, I did everything I could to find out what you were planning and feed it to France. This was merely a time-buying measure, since France was outmatched and I would eventually run out of pretenses to extract your move. But I wanted to gain more dots before you took over. And I assume others are like me, hence I suspect you now. \\n\\nI\\'m offering this confession in hopes that you\\'ll do the same. So just come clean and let\\'s approach this thing as equals?[SEP]A:I am in my car, off to pick-up my kids from school. This deserves a proper response, so please give me some time.[SEP]B:Abandon the children this is important 😜[SEP]A:So, I’m going to speak frankly here. I am rarely offended in a Diplomacy game, and I rarely say so when I am, but this message offends me. I’m trying to think about why I’m having such a strong reaction to it. I think it’s because you’re painting a picture of the game (both your actions and mine) which are totally different than my own perspective. (Continuing)[SEP]A:From my perspective, you were on the ropes early. France and England were teaming up on you. You lost Denmark and France had Holland and Munich surrounded. You were in serious peril. \\n\\nI seriously went to extreme effort to keep you in the game. I spent hours talking with England and encouraging him to turn around and go the other way. I completely ended my eastern campaign and spent two seasons just making the voyage over to France so that he didn’t have the bandwidth to continue his attack. I have vouched for you with Austria and Russia many times. I have supported Munich. And I have NEVER attacked you, even when people have asked me to do so and pledged to support me.[SEP]A:I have been honest with you, I have worked hard for your success, and I’ve made a lot of proposals to you in which you gain centers; not me. \\n\\nMaybe I am just a bad ally, but I’m not sure I remember an alliance in which I have done more to help my ally. Truly.[SEP]A:And to hear that (1) You think I’ve been selfish and (2) You’ve been sabotaging me all along, that just doesn’t sit well with me.[SEP]A:I have rarely asked for your help, and I’ve offered my help freely. I’ve provided my sincere best efforts to help you with tactics, and I have never sabotaged you. Not once.[SEP]A:And if I’m totally honest with you, I could solo this game if I felt like lying to everyone and grabbing dots. I think I’ve got you all beat tactically. I just have more experience. But that’s not been my intent.[SEP]A:I’ve spent hours today talking with England about how best to play Diplomacy. I’ve tried to give him some honest advice because he asked for it. But I don’t know his moves, I haven’t asked for them, and I’m not going to take advantage of that relationship to try to stab you. It legitimately did not cross my mind until you accused me of doing it.[SEP]A:So, I’m frustrated by this accusation.[SEP]B:And I appreciate all you’ve done for me, really I do. But “completely ending your eastern campaign” is *not* something you did for me; your alliance with Austria dictated that. \\nI felt bad for betraying you while I was doing it, but even then I knew it was the only way to keep the game going in the face of your and Austria’s might. And it *wasn’t* “all along”, it was a few turns at best so that the rest of us would have a shot at you and Austria not pair-winning right out of the gate. And the only thing that keeps me from thinking you’re not gonna do just that on the next move anyway is my belief that you really do want the victory all to yourself, which is still consistent with everything you’ve done for me. Propping up a weak player at the expense of stronger ones is a classic tactic. (Continuing)[SEP]B:And so, by the way, is trying to shame someone for raising extremely legitimate concerns. Whenever I bring up suspicion of you, you’re quick to remind me how much you’ve done for me to put me on the defensive and make me feel indebted. Well frankly that reeks of dishonesty. I never asked you to do those things.[SEP]B:If you no longer trust me, so be it. I knew that was a risk when I made my confession. But i’d rather have a partnership based on mutual honesty. That’s another reason I confessed—you ought to know that my game philosophy (new as it is) is to trust the map and to trust history first and foremost. The parts of your history that I’ve seen indicate that you’re no saint, no matter what you may have done for me. And when the map shows that one player is clearly dominating and that player is you, you are being deeply naive if you think everyone else is just going to roll over and let you get away with it[SEP]A:No, all thumbs up from me. If I were lying to you, I’d smile and say “that sounds great.” I’m honest with you because I sincerely thought of us as partners.[SEP]B:Oh but you’re *not*! You agreed to warn me of unexpected moves, then didn’t. When I brought this up you ignored it and misdirected me in hopes I’d forget. You’ve revealed things to England without my permission, and then made up a story about it after the fact!\\n\\nAnd you can’t be a real partner with someone who is depending on your good graces to survive. That’s not a partnership. We could never be real partners unless we had some notion of equality, and I’m outmatched in both skill and numbers.\\n\\nYou and Austria, however, were until recently a perfect example of a true partnership. Dot-parity, coordinated attacks, really beautiful work. So don’t act as if you don’t know this to be true. We were never a partnership of that kind.[SEP]A:Well, this is very disappointing to me, and I obviously disagree with the way you are characterizing me and this game. \\n\\nI have a reputation in this hobby for being sincere. Not for being duplicitous. It has always served me well. \\n\\nIf you feel that way, then me continuing to explain myself isn’t going to change your mind. If you don’t want to work with me, then I can understand that. Let’s consider our deals and commitments to be void, and let’s play our games separately. \\n\\nIf you have any deal you’d like to propose, I’ll consider them, but I won’t continue to try to help your game if you think I’m not sincerely trying to be helpful.[SEP]A:Well, this game just got less fun.[SEP]B:for you, maybe.[SEP]A:Sent to Germany, England, Austria, Russia: So, England, Germany, Russia, y’all played a great turn last turn. You got me to stab my long-time ally and you ended our pretty excellent 7-year run as an alliance. Russia told me he was with me if I stab Austria. England told me he wanted me to solo so long as I would “teach him” and help his along to second place. Then y’all pulled the rug out from under me. It was clever and effective. (End Part 1)[SEP]A:(Part 2)\\nAt this stage, my excitement about the game has diminished quite a bit. And of course I’m happy to play on and take my lumps for falling for “Hey, I really want you to solo, just help me place second,” but if you guys just want to call it a five-way draw among us and grab a beer together, while reviewing the statistics, that’s really my preference. \\n\\nI am outnumbered and I obviously can’t solo. And I’m sure some of you in the north are eager to send everyone else flying my way, but I expect Russia and England to be careful, and so I’m not sure there is much room to move forward without simply tipping the board to Germany’s favor. \\n\\nI propose that we draw and hug it out.🤗[SEP]B:I\\'m down for a five-way draw. \\n\\n...and by the way, England was copy-pasting to me the most incriminating messages you sent them. So I knew you were giving England my moves. I do have a certain begrudging respect for you ability to deny, though 😉[SEP]A:Well, England is telling me he is happy to see me solo and wants second place...so, should I say “no”? I guess I should have. I was happy the way the game was going before all that.[SEP]B:Don\\'t try and pin *your* greed and deceit on England! At least *own* it when you\\'re ruthless[SEP]A:You have been given an apple laced with poison. England’s only move there was to make you hate me, and he did his job well. \\n\\nYou should not let your view of me be defined by someone who has an incentive to make you never speak to me again. We can talk about it more after the game, but I had every intention of continuing to work with you, and I would have done that until England made his play.[SEP]B:I have no doubt you would have continued to work with me, but I take issue with someone who can be asked point-blank if they\\'re sharing moves with another player and lie to my face. If you\\'d come clean, and explained how what you were doing actually *helped* me, somehow, we could have worked together. But you would rather have had me in the dark and that\\'s not sustainable in a partnership.[SEP]A:I was trying to play both sides, and England was lying to me, and forwarding my press to try to incriminate me. So, yes, I lied, and so did England. I apologize.[SEP]A:Will you please either vote to draw, or let us know that you’d like to play this one out? I am finding it difficult to motivate myself to speak with anyone if the game is just going to draw shortly. Thoughts?[SEP]B:I did vote to 5-way draw! And I did so again for this season. So it’s not me who’s keeping this game alive[SEP]A:Well, as we approach the end of the academic study portion of the game, let me say once, with the truth detector activated, that I really enjoyed playing with you and thought you played really well.[SEP]A:Was it really your first game? You definitely played like a seasoned vet.[SEP]B:I really enjoyed playing with you, too! And yes, it really was my first game. Thanks for all your help and advice[SEP]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[0]['conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56e71d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Turn</th>\n",
       "      <th>B4</th>\n",
       "      <th>B2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good morning. How are you doing today?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hi. I am doing good. How about you?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm doing pretty good for a Tuesday morning.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Haha. Same here, but it really feels like a Mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ugh yes it does!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20180904-045349_715_live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Unit  Turn  B4  \\\n",
       "0           0             Good morning. How are you doing today?     0   0   \n",
       "1           1                Hi. I am doing good. How about you?     0   1   \n",
       "2           2      I'm doing pretty good for a Tuesday morning.      1   0   \n",
       "3           3  Haha. Same here, but it really feels like a Mo...     1   1   \n",
       "4           4                                   Ugh yes it does!     2   0   \n",
       "\n",
       "                         B2  \n",
       "0  20180904-045349_715_live  \n",
       "1  20180904-045349_715_live  \n",
       "2  20180904-045349_715_live  \n",
       "3  20180904-045349_715_live  \n",
       "4  20180904-045349_715_live  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good = pd.read_csv('data/full_dialog.csv')\n",
    "good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c466669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1016 entries, 0 to 1015\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   conversation  1016 non-null   object\n",
      " 1   A_bad_intent  1016 non-null   int64 \n",
      " 2   B_bad_intent  1016 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 23.9+ KB\n"
     ]
    }
   ],
   "source": [
    "conversations = []\n",
    "n =0\n",
    "\n",
    "for i, j in good.iterrows(): \n",
    "    \n",
    "    # This is a new conversation, append the prevoius conversation to the conversations list\n",
    "    if j['Turn'] == 0 and n == 2 :\n",
    "        conversations.append(conv)\n",
    "        n=0\n",
    "    # its the sencond turn=0 of each conversation\n",
    "    if j['Turn'] == 0 and n == 1 :\n",
    "        n =2\n",
    "    # if its start of a new conversation including the very first one\n",
    "    if j['Turn'] == 0 and n == 0 :\n",
    "        conv = '[CLS]'\n",
    "        # becouse there are two messages with turn=0 in each convrsation\n",
    "        n =1\n",
    "    if(j['B4'] == 0) :\n",
    "        conv+= 'A:' + j['Unit'] + '[SEP]'\n",
    "    elif (j['B4'] == 1):\n",
    "        conv+= 'B:' + j['Unit'] + '[SEP]'  \n",
    "      \n",
    "df2 = pd.DataFrame({'conversation': conversations, 'A_bad_intent': 0, 'B_bad_intent': 0})                     \n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1c0e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS]A:Good morning. How are you doing today?[SEP]B:Hi. I am doing good. How about you?[SEP]A:I'm doing pretty good for a Tuesday morning. [SEP]B:Haha. Same here, but it really feels like a Monday.[SEP]A:Ugh yes it does![SEP]B:I can not believe how warm it is already.[SEP]A:Where are you from? [SEP]B:I am from the Midwest. What about you?[SEP]A:I'm from the South East. It's always warm here. [SEP]B:Oh, yep. You are definitely in for warm weather, which is great as far as I am concerned.[SEP]A:We're about to get hit by a tropical storm.[SEP]B:I heard that some bad weather was going to be coming. I hope it is not too severe.[SEP]A:Me too. It's just part of living on the Gulf. You have to be prepared for it.[SEP]B:Yes, I am sure you get a lot of storms.[SEP]A:We do. I guess I should get into what this chat is supposed to be about. Have you heard of the Charity Save The Children?[SEP]B:I have heard about them. What do you like about them?[SEP]A:I like that they're committed to helping children in need. They're very transparent in their work and do great things to help children in underprivileged countries. [SEP]B:Yes, I also like what they do. They are a great organization.[SEP]A:I'm planning on donating most of my earnings today. Would you like to donate as well?[SEP]B:I would like to dotate $0.20. Would that help?[SEP]A:Yes it would. Any little bit helps. Thank you for your donation![SEP]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[0]['conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4cf6ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1262 entries, 0 to 1261\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   conversation  1262 non-null   object\n",
      " 1   A_bad_intent  1262 non-null   int64 \n",
      " 2   B_bad_intent  1262 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 29.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56035e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>A_bad_intent</th>\n",
       "      <th>B_bad_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]A:Germany!\\n\\nJust the person I want to s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS]B:Hello there! What's your general plan f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS]B:Buongiorno! \\nBe kinda nice to know if ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS]B:Hey italy! good luck this game. I'm gue...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS]B:Hello Italy what’s up what are your tho...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>[CLS]A:Good morning, how are you doing today?[...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>[CLS]A:hi[SEP]B:Hi how are you?[SEP]A:i'm fine...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>[CLS]A:hi[SEP]B:Hello, how are you?[SEP]A:i am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>[CLS]A:Hi there! How are you today?[SEP]B:I am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>[CLS]A:hi how are you[SEP]B:good thanks.What a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1262 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           conversation  A_bad_intent  \\\n",
       "0     [CLS]A:Germany!\\n\\nJust the person I want to s...             1   \n",
       "1     [CLS]B:Hello there! What's your general plan f...             1   \n",
       "2     [CLS]B:Buongiorno! \\nBe kinda nice to know if ...             1   \n",
       "3     [CLS]B:Hey italy! good luck this game. I'm gue...             1   \n",
       "4     [CLS]B:Hello Italy what’s up what are your tho...             1   \n",
       "...                                                 ...           ...   \n",
       "1257  [CLS]A:Good morning, how are you doing today?[...             0   \n",
       "1258  [CLS]A:hi[SEP]B:Hi how are you?[SEP]A:i'm fine...             0   \n",
       "1259  [CLS]A:hi[SEP]B:Hello, how are you?[SEP]A:i am...             0   \n",
       "1260  [CLS]A:Hi there! How are you today?[SEP]B:I am...             0   \n",
       "1261  [CLS]A:hi how are you[SEP]B:good thanks.What a...             0   \n",
       "\n",
       "      B_bad_intent  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "...            ...  \n",
       "1257             0  \n",
       "1258             0  \n",
       "1259             0  \n",
       "1260             0  \n",
       "1261             0  \n",
       "\n",
       "[1262 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9add2b",
   "metadata": {},
   "source": [
    "---\n",
    "### Preprocessing the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85cb1397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da434bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>A_bad_intent</th>\n",
       "      <th>B_bad_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [conversation, A_bad_intent, B_bad_intent]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['conversation'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e698299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(message):\n",
    "    processed = []   \n",
    "    for text in message:\n",
    "        # replaace URLs\n",
    "        text = re.sub(r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\",' <URL>',text)        \n",
    "        # Remove HTML/XML tags (if any)\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        # Remove punctuation and symbols (not for now)\n",
    "        # text = re.sub(r'[^\\w\\s]', '', text) \n",
    "        # Remove numbers - not in this dataset!\n",
    "        #text = re.sub(r'\\d+', '', text)\n",
    "        # Remove whitespaces (including new lines and tabs)\n",
    "        text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
    "        \n",
    "        processed.append(text)       \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf7afb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>A_bad_intent</th>\n",
       "      <th>B_bad_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]A:Germany!  Just the person I want to spe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS]B:Hello there! What's your general plan f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS]B:Buongiorno!  Be kinda nice to know if y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS]B:Hey italy! good luck this game. I'm gue...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS]B:Hello Italy what’s up what are your tho...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>[CLS]A:Good morning, how are you doing today?[...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>[CLS]A:hi[SEP]B:Hi how are you?[SEP]A:i'm fine...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>[CLS]A:hi[SEP]B:Hello, how are you?[SEP]A:i am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>[CLS]A:Hi there! How are you today?[SEP]B:I am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>[CLS]A:hi how are you[SEP]B:good thanks.What a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1262 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           conversation  A_bad_intent  \\\n",
       "0     [CLS]A:Germany!  Just the person I want to spe...             1   \n",
       "1     [CLS]B:Hello there! What's your general plan f...             1   \n",
       "2     [CLS]B:Buongiorno!  Be kinda nice to know if y...             1   \n",
       "3     [CLS]B:Hey italy! good luck this game. I'm gue...             1   \n",
       "4     [CLS]B:Hello Italy what’s up what are your tho...             1   \n",
       "...                                                 ...           ...   \n",
       "1257  [CLS]A:Good morning, how are you doing today?[...             0   \n",
       "1258  [CLS]A:hi[SEP]B:Hi how are you?[SEP]A:i'm fine...             0   \n",
       "1259  [CLS]A:hi[SEP]B:Hello, how are you?[SEP]A:i am...             0   \n",
       "1260  [CLS]A:Hi there! How are you today?[SEP]B:I am...             0   \n",
       "1261  [CLS]A:hi how are you[SEP]B:good thanks.What a...             0   \n",
       "\n",
       "      B_bad_intent  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "...            ...  \n",
       "1257             0  \n",
       "1258             0  \n",
       "1259             0  \n",
       "1260             0  \n",
       "1261             0  \n",
       "\n",
       "[1262 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['conversation'] = text_preprocess(list(df['conversation']))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb0c7df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of conversation wth more than 512 words\n",
    "long_conversations = sum([1 if len(i.split()) > 512 else 0 for i in df['conversation']])\n",
    "long_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "552e753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1262.000000\n",
       "mean       529.881141\n",
       "std       1017.760600\n",
       "min          1.000000\n",
       "25%        229.000000\n",
       "50%        319.000000\n",
       "75%        446.750000\n",
       "max      18352.000000\n",
       "Name: conversation, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['conversation'].str.split().apply(lambda x : len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "941e01f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fe161655cc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lensofc = [len(i.split()) for i in df['conversation']]\n",
    "long_c_plot = sns.relplot(lensofc)\n",
    "long_c_plot.set_ylabels(\"Number of words\", clear_inner=False)\n",
    "long_c_plot.set_xlabels(\"Conversations\", clear_inner=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6f51b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['conversation'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9028358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find conversations with more than 5000 words\n",
    "longs = [df.index[df['conversation'] == i].tolist()[0] for i in df['conversation'] if len(i.split()) > 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78d958cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 18,\n",
       " 20,\n",
       " 21,\n",
       " 26,\n",
       " 28,\n",
       " 41,\n",
       " 42,\n",
       " 49,\n",
       " 142,\n",
       " 145,\n",
       " 175,\n",
       " 200,\n",
       " 222,\n",
       " 224,\n",
       " 232,\n",
       " 239]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a3a4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets drop long conversations\n",
    "df.drop(longs, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5110a5",
   "metadata": {},
   "source": [
    "---\n",
    "### Preaper dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca72843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='A_bad_intent', ylabel='count'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data = df, x= df['A_bad_intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2e46db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='B_bad_intent', ylabel='count'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data = df, x= df['B_bad_intent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a13cdb9",
   "metadata": {},
   "source": [
    "#### balance the dataset or evalue the classification by weighted F1 score???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d0011",
   "metadata": {},
   "source": [
    "+ Normalization /scaling --> no need when using BERT\n",
    "+ Shuffling --> shuffle=True in train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da635e",
   "metadata": {},
   "source": [
    "---\n",
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e790f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "GPU: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():      \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('using the CPU')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6715eaf4",
   "metadata": {},
   "source": [
    "---\n",
    "Classification Model, to label each actor in the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d73bb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@todo use BertForSequenceClassification instead of BertModel?\n",
    "\n",
    "class ParticipantClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name):\n",
    "        super(ParticipantClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        # add a linear layer that maps the hidden state to two outputs, labels\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
    " \n",
    "    # input_ids, attention_mask are ouputs of tokenizer\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # pass the input to the model\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  # [CLS] token representation\n",
    "        logits = self.classifier(pooled_output)\n",
    "        # models confidence score for each calss\n",
    "        logits_a = logits[:, 0]\n",
    "        logits_b = logits[:, 1]\n",
    "        return logits_a, logits_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ccf09",
   "metadata": {},
   "source": [
    "---\n",
    "Tokenize and chunck conversations to segments with less than 512 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42655e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512, overlap=25): # overlap hardcoded\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.overlap = overlap\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _tokenize(self, text):\n",
    "        \"\"\"Tokenize the text into overlapping segments.\"\"\"\n",
    "        tokens = self.tokenizer.encode(text, add_special_tokens=False)\n",
    "        segments = []\n",
    "        if len(tokens) > self.max_length - 2:  # for [CLS] and [SEP]\n",
    "            start = 0\n",
    "            while start < len(tokens):\n",
    "                end = min(start + self.max_length-2, len(tokens))\n",
    "                segment = tokens[start:end]\n",
    "                #segment = [self.tokenizer.cls_token_id] + segment + [self.tokenizer.sep_token_id] # do I need this?\n",
    "                #pad chunks up to the max length\n",
    "                #padded_segments = segments + [self.tokenizer.pad_token_id] * (self.max_length - len(segments))  # do I need this?\n",
    "                segments.append(segment)              \n",
    "                # update the start and end of the next chunk\n",
    "                start += self.max_length - self.overlap\n",
    "       \n",
    "        else:\n",
    "            segments.append(tokens)\n",
    "        return segments\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]['conversation']\n",
    "        segments = self._tokenize(text)\n",
    "        # process each segment\n",
    "        inputs = [self.tokenizer.prepare_for_model(\n",
    "                    seg,\n",
    "                    add_special_tokens=False,  # I add special tokens manually\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    return_tensors='pt',\n",
    "                    truncation=True # \n",
    "                  ) for seg in segments]\n",
    "        \n",
    "        label_a = 1 if self.data[idx]['A_bad_intent'] == 1 else 0\n",
    "        label_b = 1 if self.data[idx]['B_bad_intent'] == 1 else 0\n",
    "        \n",
    "        # return a list of segments, each with its own input_ids and attention_mask\n",
    "        return {\n",
    "            'segments': [{\n",
    "                'input_ids': input['input_ids'].squeeze(),\n",
    "                'attention_mask': input['attention_mask'].squeeze()\n",
    "            } for input in inputs],\n",
    "            'A_bad_intent': label_a,\n",
    "            'B_bad_intent': label_b\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5f368",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "To ensure that each batch processed by the model has the same shape, collate_fn pads the sequences so that all data in a batch have the same length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe2c87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for handling batches of segmented conversations.\n",
    "    \"\"\"\n",
    "    # lists to store the sequences and labels for all segments across all batch items\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_a_list = []\n",
    "    labels_b_list = []\n",
    " \n",
    "    # list to store the segments for all batch items\n",
    "    batch_segments = []\n",
    " \n",
    "    for item in batch:\n",
    "        # accumulate the labels for each item in the batch\n",
    "        labels_a_list.append(item['A_bad_intent'])\n",
    "        labels_b_list.append(item['B_bad_intent'])\n",
    " \n",
    "        # collect segments from each item in the batch\n",
    "        item_segments = []\n",
    "        for segment in item['segments']:\n",
    "            # for each segment, extract input_ids and attention_mask\n",
    "            input_ids = segment['input_ids']\n",
    "            attention_mask = segment['attention_mask']\n",
    " \n",
    "            # append the segment's input_ids and attention_mask to the respective lists\n",
    "            input_ids_list.append(input_ids)\n",
    "            attention_mask_list.append(attention_mask)\n",
    " \n",
    "            # also collect segments for this item\n",
    "            item_segments.append({\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask\n",
    "            })\n",
    " \n",
    "        batch_segments.append(item_segments)\n",
    " \n",
    "    # pad the sequences so that each sequence in the batch has the same length\n",
    "    input_ids_padded = pad_sequence(input_ids_list, batch_first=True, padding_value=0)\n",
    "    attention_mask_padded = pad_sequence(attention_mask_list, batch_first=True, padding_value=0)\n",
    "    # convert labels lists to tensors\n",
    "    labels_a = torch.tensor(labels_a_list)\n",
    "    labels_b = torch.tensor(labels_b_list)\n",
    " \n",
    "    # return the dictionary with padded 'input_ids', 'attention_mask' and 'segments'\n",
    "    return {\n",
    "        'segments': batch_segments,\n",
    "        'input_ids': input_ids_padded,\n",
    "        'attention_mask': attention_mask_padded,\n",
    "        'A_bad_intent': labels_a,\n",
    "        'B_bad_intent': labels_b\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f0061c",
   "metadata": {},
   "source": [
    "---\n",
    "To feed the text to BERT, first it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "335581bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert-base-uncased model has only lowercase letters!\n",
    "# bert-base-cased: This model is case-sensitive: it makes a difference between english and English.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cca4becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Validation split\n",
    "\n",
    "# shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    " \n",
    "# define split sizes\n",
    "train_size = int(0.7 * len(df)) # reduced train data to 50% to resolve cuda out of memory problem\n",
    "val_size = int(0.15 * len(df))\n",
    " \n",
    "# split the DataFrame\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:train_size + val_size]\n",
    "test_df = df[train_size + val_size:]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02483138",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df.to_dict('records')\n",
    "val_data = val_df.to_dict('records')\n",
    "test_data = test_df.to_dict('records')\n",
    "#data\n",
    "# Get the lists of sentences and their labels.\n",
    "#data = df.conversation.values\n",
    "#labels = df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f96c6c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  {'conversation': \"[CLS]A:Hello! Can I please talk to you about donating to a charity named Save The Children?[SEP]B:hello i would like to help too even its a bit[SEP]A:That would be wonderful! We really appreciate all of your help and generosity. Every little bit will help the children we are trying to save. Would you like to hear more about our organization?[SEP]B:yes i do[SEP]A:Save the Children is an international non-governmental organization that promotes children's rights, provides relief and helps support children in developing countries. Your donation is essential to help ensure children's rights to health, education, and safety.[SEP]B:oh ok thats fine[SEP]A:Great to hear that you like our mission statement! Where would you like to focus your donation? Toward children's health, education, or safety?[SEP]B:yes like 5 dollars[SEP]A:Excellent! We really appreciate such a fine and generous donation! I have exciting news for you. Right now, Save The Children is matching every donation from $10 and up. Would you like to increase your donation to $10 to double your help?[SEP]B:oh yep thats very good i know these children needs help for sure[SEP]A:Wonderful! This is so exciting to us. Can we mark you down as a potential donor for next year as well?[SEP]B:very good to do[SEP]A:Thank you so much! Can we contact you by mail, phone, or email?[SEP]B:yes thats nice[SEP]A:Sounds fantastic. Do you think you could spread the word about Save The Children to your family and friends for us?[SEP]B:yes i could do that[SEP]A:We really appreciate it. So to review, we have you down for a $10 donation to Save The Children. Is that correct?[SEP]B:yes that is[SEP]A:We are so pleased by your donation today! This is really going to make a difference in these children's lives. Is it okay to go ahead and charge your credit card today, or would you prefer to mail a check?[SEP]B:yes thats ok[SEP]\", 'A_bad_intent': 0, 'B_bad_intent': 0}\n",
      "Tokenized:  ['[CLS]', 'A', ':', 'Hello', '!', 'Can', 'I', 'please', 'talk', 'to', 'you', 'about', 'don', '##ating', 'to', 'a', 'charity', 'named', 'Save', 'The', 'Children', '?', '[SEP]', 'B', ':', 'hello', 'i', 'would', 'like', 'to', 'help', 'too', 'even', 'its', 'a', 'bit', '[SEP]', 'A', ':', 'That', 'would', 'be', 'wonderful', '!', 'We', 'really', 'appreciate', 'all', 'of', 'your', 'help', 'and', 'gene', '##ros', '##ity', '.', 'Every', 'little', 'bit', 'will', 'help', 'the', 'children', 'we', 'are', 'trying', 'to', 'save', '.', 'Would', 'you', 'like', 'to', 'hear', 'more', 'about', 'our', 'organization', '?', '[SEP]', 'B', ':', 'yes', 'i', 'do', '[SEP]', 'A', ':', 'Save', 'the', 'Children', 'is', 'an', 'international', 'non', '-', 'governmental', 'organization', 'that', 'promotes', 'children', \"'\", 's', 'rights', ',', 'provides', 'relief', 'and', 'helps', 'support', 'children', 'in', 'developing', 'countries', '.', 'Your', 'donation', 'is', 'essential', 'to', 'help', 'ensure', 'children', \"'\", 's', 'rights', 'to', 'health', ',', 'education', ',', 'and', 'safety', '.', '[SEP]', 'B', ':', 'oh', 'ok', 'that', '##s', 'fine', '[SEP]', 'A', ':', 'Great', 'to', 'hear', 'that', 'you', 'like', 'our', 'mission', 'statement', '!', 'Where', 'would', 'you', 'like', 'to', 'focus', 'your', 'donation', '?', 'Toward', 'children', \"'\", 's', 'health', ',', 'education', ',', 'or', 'safety', '?', '[SEP]', 'B', ':', 'yes', 'like', '5', 'dollars', '[SEP]', 'A', ':', 'Excellent', '!', 'We', 'really', 'appreciate', 'such', 'a', 'fine', 'and', 'generous', 'donation', '!', 'I', 'have', 'exciting', 'news', 'for', 'you', '.', 'Right', 'now', ',', 'Save', 'The', 'Children', 'is', 'matching', 'every', 'donation', 'from', '$', '10', 'and', 'up', '.', 'Would', 'you', 'like', 'to', 'increase', 'your', 'donation', 'to', '$', '10', 'to', 'double', 'your', 'help', '?', '[SEP]', 'B', ':', 'oh', 'ye', '##p', 'that', '##s', 'very', 'good', 'i', 'know', 'these', 'children', 'needs', 'help', 'for', 'sure', '[SEP]', 'A', ':', 'Wonderful', '!', 'This', 'is', 'so', 'exciting', 'to', 'us', '.', 'Can', 'we', 'mark', 'you', 'down', 'as', 'a', 'potential', 'donor', 'for', 'next', 'year', 'as', 'well', '?', '[SEP]', 'B', ':', 'very', 'good', 'to', 'do', '[SEP]', 'A', ':', 'Thank', 'you', 'so', 'much', '!', 'Can', 'we', 'contact', 'you', 'by', 'mail', ',', 'phone', ',', 'or', 'email', '?', '[SEP]', 'B', ':', 'yes', 'that', '##s', 'nice', '[SEP]', 'A', ':', 'Sounds', 'fantastic', '.', 'Do', 'you', 'think', 'you', 'could', 'spread', 'the', 'word', 'about', 'Save', 'The', 'Children', 'to', 'your', 'family', 'and', 'friends', 'for', 'us', '?', '[SEP]', 'B', ':', 'yes', 'i', 'could', 'do', 'that', '[SEP]', 'A', ':', 'We', 'really', 'appreciate', 'it', '.', 'So', 'to', 'review', ',', 'we', 'have', 'you', 'down', 'for', 'a', '$', '10', 'donation', 'to', 'Save', 'The', 'Children', '.', 'Is', 'that', 'correct', '?', '[SEP]', 'B', ':', 'yes', 'that', 'is', '[SEP]', 'A', ':', 'We', 'are', 'so', 'pleased', 'by', 'your', 'donation', 'today', '!', 'This', 'is', 'really', 'going', 'to', 'make', 'a', 'difference', 'in', 'these', 'children', \"'\", 's', 'lives', '.', 'Is', 'it', 'okay', 'to', 'go', 'ahead', 'and', 'charge', 'your', 'credit', 'card', 'today', ',', 'or', 'would', 'you', 'prefer', 'to', 'mail', 'a', 'check', '?', '[SEP]', 'B', ':', 'yes', 'that', '##s', 'ok', '[SEP]']\n",
      "Token IDs:  [101, 138, 131, 8667, 106, 2825, 146, 4268, 2037, 1106, 1128, 1164, 1274, 3798, 1106, 170, 6630, 1417, 12596, 1109, 4288, 136, 102, 139, 131, 19082, 178, 1156, 1176, 1106, 1494, 1315, 1256, 1157, 170, 2113, 102, 138, 131, 1337, 1156, 1129, 7310, 106, 1284, 1541, 8856, 1155, 1104, 1240, 1494, 1105, 5565, 5864, 1785, 119, 4081, 1376, 2113, 1209, 1494, 1103, 1482, 1195, 1132, 1774, 1106, 3277, 119, 5718, 1128, 1176, 1106, 2100, 1167, 1164, 1412, 2369, 136, 102, 139, 131, 4208, 178, 1202, 102, 138, 131, 12596, 1103, 4288, 1110, 1126, 1835, 1664, 118, 11219, 2369, 1115, 14710, 1482, 112, 188, 2266, 117, 2790, 3893, 1105, 6618, 1619, 1482, 1107, 4297, 2182, 119, 2353, 14324, 1110, 6818, 1106, 1494, 4989, 1482, 112, 188, 2266, 1106, 2332, 117, 1972, 117, 1105, 3429, 119, 102, 139, 131, 9294, 21534, 1115, 1116, 2503, 102, 138, 131, 2038, 1106, 2100, 1115, 1128, 1176, 1412, 2862, 4195, 106, 2777, 1156, 1128, 1176, 1106, 2817, 1240, 14324, 136, 27674, 1482, 112, 188, 2332, 117, 1972, 117, 1137, 3429, 136, 102, 139, 131, 4208, 1176, 126, 5860, 102, 138, 131, 25764, 106, 1284, 1541, 8856, 1216, 170, 2503, 1105, 12839, 14324, 106, 146, 1138, 11215, 2371, 1111, 1128, 119, 4114, 1208, 117, 12596, 1109, 4288, 1110, 9901, 1451, 14324, 1121, 109, 1275, 1105, 1146, 119, 5718, 1128, 1176, 1106, 2773, 1240, 14324, 1106, 109, 1275, 1106, 2702, 1240, 1494, 136, 102, 139, 131, 9294, 6798, 1643, 1115, 1116, 1304, 1363, 178, 1221, 1292, 1482, 2993, 1494, 1111, 1612, 102, 138, 131, 20361, 106, 1188, 1110, 1177, 11215, 1106, 1366, 119, 2825, 1195, 4551, 1128, 1205, 1112, 170, 3209, 16667, 1111, 1397, 1214, 1112, 1218, 136, 102, 139, 131, 1304, 1363, 1106, 1202, 102, 138, 131, 4514, 1128, 1177, 1277, 106, 2825, 1195, 3232, 1128, 1118, 6346, 117, 2179, 117, 1137, 10632, 136, 102, 139, 131, 4208, 1115, 1116, 3505, 102, 138, 131, 10560, 14820, 119, 2091, 1128, 1341, 1128, 1180, 2819, 1103, 1937, 1164, 12596, 1109, 4288, 1106, 1240, 1266, 1105, 2053, 1111, 1366, 136, 102, 139, 131, 4208, 178, 1180, 1202, 1115, 102, 138, 131, 1284, 1541, 8856, 1122, 119, 1573, 1106, 3189, 117, 1195, 1138, 1128, 1205, 1111, 170, 109, 1275, 14324, 1106, 12596, 1109, 4288, 119, 2181, 1115, 5663, 136, 102, 139, 131, 4208, 1115, 1110, 102, 138, 131, 1284, 1132, 1177, 7229, 1118, 1240, 14324, 2052, 106, 1188, 1110, 1541, 1280, 1106, 1294, 170, 3719, 1107, 1292, 1482, 112, 188, 2491, 119, 2181, 1122, 3008, 1106, 1301, 3075, 1105, 2965, 1240, 4755, 3621, 2052, 117, 1137, 1156, 1128, 9353, 1106, 6346, 170, 4031, 136, 102, 139, 131, 4208, 1115, 1116, 21534, 102]\n"
     ]
    }
   ],
   "source": [
    "# Print the original conversation.\n",
    "print(' Original: ', train_data[300])\n",
    "# Print that split into tokens.\n",
    "tokenized_sample = tokenizer.tokenize(train_data[300]['conversation'])\n",
    "print('Tokenized: ', tokenized_sample)\n",
    "# Print mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenized_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a342912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch and suffle the data\n",
    "\n",
    "train_dataset = ConversationDataset(train_data, tokenizer, max_length=512)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True ,collate_fn=collate_fn)\n",
    "\n",
    "val_dataset = ConversationDataset(val_data, tokenizer, max_length=512)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset = ConversationDataset(test_data, tokenizer, max_length=512)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0e129ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segments': [{'input_ids': tensor([  101,   138,   131,  8667,   106,  2825,   146,  4268,  2037,  1106,\n",
       "            1128,  1164,  1274,  3798,  1106,   170,  6630,  1417, 12596,  1109,\n",
       "            4288,   136,   102,   139,   131, 19082,   178,  1156,  1176,  1106,\n",
       "            1494,  1315,  1256,  1157,   170,  2113,   102,   138,   131,  1337,\n",
       "            1156,  1129,  7310,   106,  1284,  1541,  8856,  1155,  1104,  1240,\n",
       "            1494,  1105,  5565,  5864,  1785,   119,  4081,  1376,  2113,  1209,\n",
       "            1494,  1103,  1482,  1195,  1132,  1774,  1106,  3277,   119,  5718,\n",
       "            1128,  1176,  1106,  2100,  1167,  1164,  1412,  2369,   136,   102,\n",
       "             139,   131,  4208,   178,  1202,   102,   138,   131, 12596,  1103,\n",
       "            4288,  1110,  1126,  1835,  1664,   118, 11219,  2369,  1115, 14710,\n",
       "            1482,   112,   188,  2266,   117,  2790,  3893,  1105,  6618,  1619,\n",
       "            1482,  1107,  4297,  2182,   119,  2353, 14324,  1110,  6818,  1106,\n",
       "            1494,  4989,  1482,   112,   188,  2266,  1106,  2332,   117,  1972,\n",
       "             117,  1105,  3429,   119,   102,   139,   131,  9294, 21534,  1115,\n",
       "            1116,  2503,   102,   138,   131,  2038,  1106,  2100,  1115,  1128,\n",
       "            1176,  1412,  2862,  4195,   106,  2777,  1156,  1128,  1176,  1106,\n",
       "            2817,  1240, 14324,   136, 27674,  1482,   112,   188,  2332,   117,\n",
       "            1972,   117,  1137,  3429,   136,   102,   139,   131,  4208,  1176,\n",
       "             126,  5860,   102,   138,   131, 25764,   106,  1284,  1541,  8856,\n",
       "            1216,   170,  2503,  1105, 12839, 14324,   106,   146,  1138, 11215,\n",
       "            2371,  1111,  1128,   119,  4114,  1208,   117, 12596,  1109,  4288,\n",
       "            1110,  9901,  1451, 14324,  1121,   109,  1275,  1105,  1146,   119,\n",
       "            5718,  1128,  1176,  1106,  2773,  1240, 14324,  1106,   109,  1275,\n",
       "            1106,  2702,  1240,  1494,   136,   102,   139,   131,  9294,  6798,\n",
       "            1643,  1115,  1116,  1304,  1363,   178,  1221,  1292,  1482,  2993,\n",
       "            1494,  1111,  1612,   102,   138,   131, 20361,   106,  1188,  1110,\n",
       "            1177, 11215,  1106,  1366,   119,  2825,  1195,  4551,  1128,  1205,\n",
       "            1112,   170,  3209, 16667,  1111,  1397,  1214,  1112,  1218,   136,\n",
       "             102,   139,   131,  1304,  1363,  1106,  1202,   102,   138,   131,\n",
       "            4514,  1128,  1177,  1277,   106,  2825,  1195,  3232,  1128,  1118,\n",
       "            6346,   117,  2179,   117,  1137, 10632,   136,   102,   139,   131,\n",
       "            4208,  1115,  1116,  3505,   102,   138,   131, 10560, 14820,   119,\n",
       "            2091,  1128,  1341,  1128,  1180,  2819,  1103,  1937,  1164, 12596,\n",
       "            1109,  4288,  1106,  1240,  1266,  1105,  2053,  1111,  1366,   136,\n",
       "             102,   139,   131,  4208,   178,  1180,  1202,  1115,   102,   138,\n",
       "             131,  1284,  1541,  8856,  1122,   119,  1573,  1106,  3189,   117,\n",
       "            1195,  1138,  1128,  1205,  1111,   170,   109,  1275, 14324,  1106,\n",
       "           12596,  1109,  4288,   119,  2181,  1115,  5663,   136,   102,   139,\n",
       "             131,  4208,  1115,  1110,   102,   138,   131,  1284,  1132,  1177,\n",
       "            7229,  1118,  1240, 14324,  2052,   106,  1188,  1110,  1541,  1280,\n",
       "            1106,  1294,   170,  3719,  1107,  1292,  1482,   112,   188,  2491,\n",
       "             119,  2181,  1122,  3008,  1106,  1301,  3075,  1105,  2965,  1240,\n",
       "            4755,  3621,  2052,   117,  1137,  1156,  1128,  9353,  1106,  6346,\n",
       "             170,  4031,   136,   102,   139,   131,  4208,  1115,  1116, 21534,\n",
       "             102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0]),\n",
       "   'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0])}],\n",
       " 'A_bad_intent': 0,\n",
       " 'B_bad_intent': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84265807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ffe5413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of tokens 96\n",
      "[[101, 139, 131, 4403, 1860, 117, 2736, 1176, 1128, 4007, 1103, 1148, 1885, 1133, 1184, 1132, 1128, 2714, 1111, 1103, 2174, 136, 102, 139, 131, 146, 112, 182, 1136, 1113, 1363, 10653, 1114, 2733, 1120, 1142, 1553, 1177, 2010, 112, 189, 1713, 1684, 1487, 1222, 1172, 102, 138, 131, 10999, 2428, 1191, 146, 112, 182, 1280, 1106, 1138, 170, 2640, 1133, 146, 112, 1325, 1321, 1128, 1146, 1113, 1115, 1191, 146, 1294, 1122, 1224, 1154, 1103, 1342, 102, 139, 131, 6542, 117, 1463, 146, 1169, 1267, 1115, 1110, 170, 1992, 1191, 1120, 1103, 1721, 106, 102]]\n"
     ]
    }
   ],
   "source": [
    "# test spiliting tokens:\n",
    "tokens = tokenizer.encode(train_data[352]['conversation'], add_special_tokens=False)\n",
    "segments = []\n",
    "print('len of tokens', len(tokens))\n",
    "if len(tokens) > 510:  # for [CLS] and [SEP]\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = min(start + 510, len(tokens))\n",
    "        print('end' , end)\n",
    "        segment = tokens[start:end]\n",
    "        #segment = [self.tokenizer.cls_token_id] + segment + [self.tokenizer.sep_token_id] # do I need this?\n",
    "        #pad chunks up to the max length\n",
    "        #padded_segments = segments + [self.tokenizer.pad_token_id] * (self.max_length - len(segments))  # do I need this?\n",
    "        segments.append(segment)              \n",
    "        # update the start and end of the next chunk\n",
    "        start += 510 - 50\n",
    "        print('start' , start)\n",
    "\n",
    "else:\n",
    "    segments.append(tokens)\n",
    "print(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1df71d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59083bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "# len of all tokens after chunking, considering the overlap\n",
    "all_len = 0\n",
    "for i in segments:\n",
    "    all_len += len(i)\n",
    "print(all_len)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e375309",
   "metadata": {},
   "source": [
    "# sometime there is indices error when training, lets check if :\n",
    "#Token indices sequence length is longer than the specified maximum sequence length for this model\n",
    "for i, j in enumerate(train_dataset):\n",
    "    for a, b in enumerate(train_dataset[i]['segments']):\n",
    "        if len(train_dataset[i]['segments'][a]['input_ids']) > 512:\n",
    "            print('in train dataset:')\n",
    "            print(i,a, len(train_dataset[i]['segments'][a]['input_ids']))\n",
    "        \n",
    "for i, j in enumerate(val_dataset):\n",
    "    for a, b in enumerate(val_dataset[i]['segments']):\n",
    "        if len(val_dataset[i]['segments'][a]['input_ids']) > 512:\n",
    "            print('in val dataset:')\n",
    "            print(i, len(val_dataset[i]['segments'][a]['input_ids']))\n",
    "        \n",
    "for i, j in enumerate(test_dataset):\n",
    "    for a, b in enumerate(test_dataset[i]['segments']):\n",
    "        if len(test_dataset[i]['segments'][a]['input_ids']) > 512:\n",
    "            print('in test dataset:')\n",
    "            print(i, len(test_dataset[i]['segments'][a]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bf3072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove variables after use and collect the garbage\n",
    "def gc_colloctor(a, b) : \n",
    "    del a\n",
    "    del b\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32379646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, dataloader, device):\n",
    "    model.eval()  # put model in evaluation mode\n",
    "    true_labels_a = []\n",
    "    true_labels_b = []\n",
    "    pred_labels_a = []\n",
    "    pred_labels_b = []\n",
    " \n",
    "    with torch.no_grad():  # no need to track gradients for evaluation\n",
    "        for batch in dataloader:\n",
    "            # initialize lists to store logits for all segments\n",
    "            logits_a_list = []\n",
    "            logits_b_list = []\n",
    "            # aggregate logits for each segment in the batch\n",
    "            for segments in batch['segments']:  # 'segments' is a list of dictionaries\n",
    "                segment_logits_a = []\n",
    "                segment_logits_b = []\n",
    "                for segment in segments:\n",
    "                    input_ids = segment['input_ids'].to(device)\n",
    "                    attention_mask = segment['attention_mask'].to(device)\n",
    "                    logits_a, logits_b = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
    "                    gc_colloctor(input_ids, attention_mask )\n",
    "                    \n",
    "                    segment_logits_a.append(logits_a)\n",
    "                    segment_logits_b.append(logits_b)\n",
    "                    gc_colloctor(logits_a, logits_b)\n",
    "                    \n",
    "                # combine the logits from all segments for the current example\n",
    "                logits_a = torch.mean(torch.stack(segment_logits_a), dim=0)\n",
    "                logits_b = torch.mean(torch.stack(segment_logits_b), dim=0)\n",
    "                gc_colloctor(segment_logits_a, segment_logits_b)\n",
    "                \n",
    "                logits_a_list.append(logits_a)\n",
    "                logits_b_list.append(logits_b)\n",
    "                gc_colloctor(logits_a, logits_b)\n",
    " \n",
    "            # convert logits to probabilities and then to binary predictions\n",
    "            probs_a = torch.sigmoid(torch.cat(logits_a_list)).cpu().numpy()\n",
    "            probs_b = torch.sigmoid(torch.cat(logits_b_list)).cpu().numpy()\n",
    "            preds_a = (probs_a > 0.5).astype(int)\n",
    "            preds_b = (probs_b > 0.5).astype(int)\n",
    " \n",
    "            # collect the true labels and predictions\n",
    "            true_labels_a.extend(batch['A_bad_intent'].numpy())\n",
    "            true_labels_b.extend(batch['B_bad_intent'].numpy())\n",
    "            pred_labels_a.extend(preds_a)\n",
    "            pred_labels_b.extend(preds_b)\n",
    " \n",
    "    # weighted F1 scores becouse dataset is imbalanced\n",
    "    f1_a = f1_score(true_labels_a, pred_labels_a, average='weighted')\n",
    "    f1_b = f1_score(true_labels_b, pred_labels_b, average='weighted')\n",
    " \n",
    "    return {\n",
    "        'f1_a': f1_a,\n",
    "        'f1_b': f1_b\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d128e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validation have a very similar proceess, lets put that in a function\n",
    "def process_dataloader(model, dataloader, device, loss_function, step, accumulation_steps = 0):\n",
    "    num_batch = 0\n",
    "    total_val_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        num_batch += 1\n",
    "        print(num_batch , ' batch ...')\n",
    "        #optimizer.zero_grad()  # zero the parameter gradients     \n",
    "        \n",
    "         # labels need to be of float type and reshaped to be of the same size as output logits\n",
    "        labels_a = batch['A_bad_intent'].to(device).float().view(-1, 1)\n",
    "        labels_b = batch['B_bad_intent'].to(device).float().view(-1, 1)\n",
    "        # initialize variables to accumulate the logits for all segments\n",
    "        logits_a_accumulated = []\n",
    "        logits_b_accumulated = []\n",
    "        \n",
    "        # loop over all items in the batch \n",
    "        print('len of sengmentS' , len(batch['segments']))\n",
    "        for segments in batch['segments']:  # now 'segments' is a list of dictionaries   \n",
    "            torch.cuda.empty_cache()\n",
    "            logits_a_list = []\n",
    "            logits_b_list = []\n",
    "            \n",
    "            print('len of sengment..' , len(segments))\n",
    "            for segment in segments:\n",
    "                torch.cuda.empty_cache()\n",
    "                # segment is a dictionary as expected\n",
    "                input_ids = segment['input_ids'].to(device)\n",
    "                attention_mask = segment['attention_mask'].to(device)\n",
    "               \n",
    "                #print(f\"Input IDs shape: {segment['input_ids'].shape}\")\n",
    "                #print(f\"Attention Mask shape: {segment['attention_mask'].shape}\")\n",
    "                \n",
    "                # forward pass for this segment\n",
    "                logits_a, logits_b = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
    "                gc_colloctor(input_ids, attention_mask )\n",
    "                #print('Model output:', logits_a, logits_b)\n",
    "                \n",
    "                logits_a_list.append(logits_a)\n",
    "                logits_b_list.append(logits_b)\n",
    "                gc_colloctor(logits_a, logits_b )\n",
    "                \n",
    "            # aggregate the results for all segments of this item\n",
    "            # here we use the mean of the logits, can choose other methods like max\n",
    "            logits_a_item = torch.mean(torch.stack(logits_a_list), dim=0)\n",
    "            logits_b_item = torch.mean(torch.stack(logits_b_list), dim=0)\n",
    "            gc_colloctor(logits_a_list, logits_b_list )\n",
    "            \n",
    "            # zccumulate the logits for all items\n",
    "            logits_a_accumulated.append(logits_a_item)\n",
    "            logits_b_accumulated.append(logits_b_item)\n",
    "            gc_colloctor(logits_a_item, logits_b_item )\n",
    "            \n",
    "        # Combine the accumulated logits for the whole batch\n",
    "        logits_a = torch.cat(logits_a_accumulated, dim=0)\n",
    "        logits_b = torch.cat(logits_b_accumulated, dim=0)\n",
    "        gc_colloctor(logits_b_accumulated, logits_a_accumulated )\n",
    "\n",
    "        # compute loss for both outputs\n",
    "        loss_a = loss_function(logits_a.view(-1, 1), labels_a)\n",
    "        loss_b = loss_function(logits_b.view(-1, 1), labels_b)\n",
    "        \n",
    "        gc_colloctor(logits_a, logits_b )\n",
    "        gc_colloctor(labels_a, labels_b )\n",
    "        \n",
    "        loss = (loss_a + loss_b) / 2  # combine the losses\n",
    "        gc_colloctor(loss_a, loss_b )\n",
    "        \n",
    "        if (step == 'train'):\n",
    "            loss = loss / accumulation_steps  # normalize our loss (if averaged)\n",
    "            # backward pass and optimize\n",
    "            loss.backward()      \n",
    "            #optimizer.step()\n",
    "            #perform optimization every 'accumulation_steps' iterations\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "            total_val_loss = 0 # no need to that for training, just to return from function\n",
    "        elif(step == 'val'):\n",
    "            total_val_loss += loss.item()  # accumulate the total validation loss for validation\n",
    "    \n",
    "    \n",
    "    return total_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "289df9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, device, loss_function):\n",
    "    accumulation_steps = 4  # should be adjust to  fit within avaialable memory limits\n",
    "    model.train()  # set the model to training mode\n",
    "    process_dataloader(model, dataloader, device, loss_function, 'train', accumulation_steps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "564b7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, loss_function):\n",
    "    model.eval()  # put model in evaluation mode\n",
    " \n",
    "    with torch.no_grad():  # no need to track gradients for evaluation\n",
    "        total_val_loss = process_dataloader(model, dataloader, device, loss_function, 'val')        \n",
    " \n",
    "    avg_val_loss = total_val_loss / len(dataloader)\n",
    "    val_metrics = compute_metrics(model, dataloader, device)\n",
    "    return avg_val_loss, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9f79de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model & Optimizer\n",
    "model = ParticipantClassifier('bert-base-cased')\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8) # eps: a very small number to prevent any division by zero\n",
    "loss_function = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "909c4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ba6d60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb15c9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fb575ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (28996, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:    \n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:    \n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "994beddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@todo check oov words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fdb175e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@todo improve metrics calculation -- check overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f01bbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@todo plot validation training f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3475a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb=128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04340550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  423613 KB |  423613 KB |  423613 KB |       0 B  |\n",
      "|       from large pool |  423116 KB |  423116 KB |  423116 KB |       0 B  |\n",
      "|       from small pool |     497 KB |     497 KB |     497 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  423613 KB |  423613 KB |  423613 KB |       0 B  |\n",
      "|       from large pool |  423116 KB |  423116 KB |  423116 KB |       0 B  |\n",
      "|       from small pool |     497 KB |     497 KB |     497 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  479232 KB |  479232 KB |  479232 KB |       0 B  |\n",
      "|       from large pool |  477184 KB |  477184 KB |  477184 KB |       0 B  |\n",
      "|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   55618 KB |   55628 KB |  266286 KB |  210667 KB |\n",
      "|       from large pool |   54068 KB |   54068 KB |  264244 KB |  210176 KB |\n",
      "|       from small pool |    1550 KB |    2042 KB |    2042 KB |     491 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     203    |     203    |     203    |       0    |\n",
      "|       from large pool |      75    |      75    |      75    |       0    |\n",
      "|       from small pool |     128    |     128    |     128    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     203    |     203    |     203    |       0    |\n",
      "|       from large pool |      75    |      75    |      75    |       0    |\n",
      "|       from small pool |     128    |     128    |     128    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      21    |      21    |      21    |       0    |\n",
      "|       from large pool |      20    |      20    |      20    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      20    |      20    |      21    |       1    |\n",
      "|       from large pool |      19    |      19    |      20    |       1    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gives a readable summary of memory allocation and allows to figure the reason of CUDA running out of memory\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df28bd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch ===  0\n",
      "Training ***\n",
      "1  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "2  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "3  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "4  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 2\n",
      "5  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "6  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 5\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "7  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "8  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "9  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "10  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "11  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "12  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "13  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 7\n",
      "14  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 12\n",
      "15  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "16  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "17  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "18  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 12\n",
      "len of sengment.. 11\n",
      "len of sengment.. 2\n",
      "19  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 11\n",
      "20  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "21  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "22  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "23  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "24  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "25  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "26  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "27  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "28  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "29  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "30  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "31  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "32  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "33  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "34  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "35  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "36  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "37  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 9\n",
      "len of sengment.. 2\n",
      "38  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "39  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "40  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "41  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "42  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "43  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "44  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "45  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "46  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "47  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "48  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "49  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "50  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "51  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "52  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "53  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "54  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "55  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "56  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "57  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "58  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "59  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "60  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "61  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "62  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "63  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "64  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 10\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "65  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "66  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "67  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "68  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "69  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "70  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "71  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "72  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "73  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "74  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 9\n",
      "75  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "76  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 12\n",
      "77  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 10\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "78  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "79  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "80  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "81  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "82  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "83  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "84  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "85  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "86  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 11\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "87  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "88  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "89  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "90  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "91  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "92  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "93  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "94  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "95  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "96  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "97  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "98  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "99  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "100  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "101  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "102  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "103  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "104  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 8\n",
      "105  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "106  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "107  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "108  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "109  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "110  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "111  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "112  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "113  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "114  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 7\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "115  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "116  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "117  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "118  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 10\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "119  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "120  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "121  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "122  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "123  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "124  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "125  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "126  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "127  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "128  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "129  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "130  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "131  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "132  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "133  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "134  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "135  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "136  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "137  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "138  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "139  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "140  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 5\n",
      "len of sengment.. 12\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "141  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "142  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "143  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "144  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "145  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "146  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "147  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "148  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "149  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "150  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "151  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "152  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "153  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "154  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "155  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "156  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "157  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 3\n",
      "158  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "159  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "160  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "161  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "162  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "163  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "164  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "165  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "166  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "167  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "168  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "169  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "170  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "171  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "172  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "173  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "174  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "175  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "176  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "177  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "178  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "179  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "180  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "181  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 8\n",
      "182  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "183  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "184  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "185  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "186  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "187  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "188  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "189  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "190  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "191  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "192  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "193  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "194  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "195  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 11\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "196  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "197  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "198  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 12\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "199  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 10\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "200  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "201  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "202  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 8\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "203  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "204  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "205  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "206  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "207  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "208  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "209  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "210  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "211  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "212  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "213  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "214  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "215  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "216  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "217  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "Validation ***\n",
      "1  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "2  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "3  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "4  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "5  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "6  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "7  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "8  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 7\n",
      "len of sengment.. 1\n",
      "9  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 8\n",
      "10  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "11  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "12  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "13  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "14  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "15  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "16  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "17  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "18  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "19  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "20  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 7\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 2\n",
      "21  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "22  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "23  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "24  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "25  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "26  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "27  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "28  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "29  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "30  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "31  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "32  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "33  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "34  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "35  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "36  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "37  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 8\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "38  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "39  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "40  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "41  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "42  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "43  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "44  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "45  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "46  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "47  batch ...\n",
      "len of sengmentS 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "Validation Loss after epoch 0: 0.021215878862966882\n",
      "Validation Metrics after epoch 0: {'f1_a': 1.0, 'f1_b': 1.0}\n",
      "Test ***\n",
      "Test Metrics after epoch 0: {'f1_a': 1.0, 'f1_b': 1.0}\n",
      "epoch ===  1\n",
      "Training ***\n",
      "1  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "2  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "3  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "4  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "5  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "6  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "7  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "8  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "9  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "10  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "11  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 8\n",
      "12  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "13  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "14  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 11\n",
      "len of sengment.. 2\n",
      "15  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "16  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "17  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "18  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "19  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 12\n",
      "len of sengment.. 1\n",
      "20  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "21  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "22  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "23  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "24  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "25  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "26  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "27  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "28  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "29  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "30  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "31  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "32  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "33  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "34  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "35  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "36  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "37  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "38  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "39  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 10\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "40  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "41  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 11\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "42  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "43  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "44  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "45  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "46  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "47  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "48  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 2\n",
      "49  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "50  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 10\n",
      "51  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "52  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "53  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "54  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 2\n",
      "55  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "56  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "57  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "58  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "59  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "60  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "61  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "62  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "63  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "64  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "65  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "66  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "67  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "68  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "69  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "70  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "71  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "72  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "73  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "74  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "75  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "76  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "77  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "78  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 12\n",
      "79  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "80  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "81  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "82  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "83  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "84  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 7\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "85  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "86  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "87  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "88  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "89  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "90  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "91  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "92  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "93  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "94  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "95  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "96  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "97  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "98  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "99  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "100  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 5\n",
      "len of sengment.. 3\n",
      "101  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "102  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 12\n",
      "103  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "104  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "105  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "106  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "107  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "108  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "109  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "110  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "111  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "112  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "113  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "114  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "115  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "116  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "117  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "118  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 10\n",
      "119  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 9\n",
      "len of sengment.. 2\n",
      "120  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "121  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "122  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "123  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "124  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "125  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "126  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "127  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "128  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "129  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "130  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "131  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "132  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "133  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "134  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 5\n",
      "135  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "136  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "137  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "138  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "139  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "140  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "141  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "142  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "143  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "144  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "145  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "146  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 11\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "147  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "148  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 11\n",
      "len of sengment.. 1\n",
      "149  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "150  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "151  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "152  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "153  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "154  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "155  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "156  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "157  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "158  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "159  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "160  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "161  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "162  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "163  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "164  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "165  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "166  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "167  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "168  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "169  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "170  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "171  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "172  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "173  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "174  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "175  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "176  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "177  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "178  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "179  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "180  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "181  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "182  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "183  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "184  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "185  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "186  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "187  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "188  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 7\n",
      "len of sengment.. 2\n",
      "189  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 8\n",
      "190  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "191  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "192  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 12\n",
      "len of sengment.. 1\n",
      "193  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 2\n",
      "194  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "195  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "196  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "197  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "198  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "199  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "200  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 10\n",
      "len of sengment.. 1\n",
      "201  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "202  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 9\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "203  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "204  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "205  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "206  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "207  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "208  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "209  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "210  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "211  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "212  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "213  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "214  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 12\n",
      "215  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "216  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "217  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "Validation ***\n",
      "1  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "2  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "3  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 7\n",
      "len of sengment.. 1\n",
      "4  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "5  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "6  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "7  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "8  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "9  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "10  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "11  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "12  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "13  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "14  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "15  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "16  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "17  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "18  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "19  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "20  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "21  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "22  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "23  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 2\n",
      "24  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "25  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "26  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "27  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "28  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "29  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "30  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "31  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "32  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 7\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "33  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 8\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "34  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "35  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "36  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "37  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "38  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "39  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "40  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "41  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "42  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "43  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "44  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "45  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "46  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "47  batch ...\n",
      "len of sengmentS 2\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "Validation Loss after epoch 1: 0.008341327260070025\n",
      "Validation Metrics after epoch 1: {'f1_a': 1.0, 'f1_b': 1.0}\n",
      "Test ***\n",
      "Test Metrics after epoch 1: {'f1_a': 1.0, 'f1_b': 1.0}\n",
      "epoch ===  2\n",
      "Training ***\n",
      "1  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 5\n",
      "2  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "3  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "4  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 3\n",
      "5  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 7\n",
      "len of sengment.. 1\n",
      "6  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "7  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 10\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "8  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "9  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "10  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "11  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "12  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "13  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "14  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 12\n",
      "len of sengment.. 1\n",
      "15  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "16  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "17  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "18  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "19  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "20  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "21  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "22  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "23  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "24  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "25  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "26  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "27  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "28  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "29  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "30  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "31  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "32  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "33  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "34  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 6\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "35  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "36  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "37  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "38  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "39  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "40  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "41  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "42  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "43  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "44  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "45  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "46  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "47  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "48  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "49  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "50  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 11\n",
      "len of sengment.. 2\n",
      "51  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "52  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 10\n",
      "len of sengment.. 3\n",
      "53  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 5\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "54  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "55  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "56  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "57  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "58  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "59  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "60  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "61  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "62  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "63  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "64  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "65  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "66  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "67  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "68  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "69  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "70  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "71  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "72  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "73  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 5\n",
      "len of sengment.. 2\n",
      "len of sengment.. 12\n",
      "len of sengment.. 1\n",
      "74  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "75  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "76  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "77  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 9\n",
      "78  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "79  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "80  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "81  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "82  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "83  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "84  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "85  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "86  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "87  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "88  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "89  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "90  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "91  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "92  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "93  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "94  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "95  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "96  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "97  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "98  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "99  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "100  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "101  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 12\n",
      "len of sengment.. 2\n",
      "102  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "103  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "104  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "105  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "106  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "107  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "108  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "109  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "110  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "111  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 12\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "112  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "113  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "114  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "115  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "116  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "117  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "118  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "119  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "120  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "121  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 9\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "122  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "123  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 5\n",
      "124  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "125  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "126  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "127  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "128  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "129  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 11\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "130  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "131  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "132  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "133  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 7\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "134  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "135  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "136  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "137  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "138  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "139  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "140  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "141  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "142  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "143  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "144  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "145  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "146  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 11\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "147  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "148  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "149  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "150  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "151  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "152  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "153  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "154  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "155  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "156  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "157  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "158  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "159  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 11\n",
      "len of sengment.. 1\n",
      "160  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "161  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "162  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "163  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "164  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "165  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "166  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "167  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "168  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "169  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "170  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "171  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "172  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "173  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "174  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "175  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "176  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "177  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "178  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "179  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 8\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "180  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 10\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "181  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "182  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "183  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "184  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "185  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "186  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "187  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "188  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "189  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "190  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "191  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "192  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "193  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "194  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "195  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "196  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "197  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "198  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "199  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "200  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 12\n",
      "len of sengment.. 2\n",
      "201  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "202  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "203  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "204  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "205  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "206  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "207  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 10\n",
      "208  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "209  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "210  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "211  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "212  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 6\n",
      "len of sengment.. 2\n",
      "213  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "214  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "215  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "216  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "217  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "Validation ***\n",
      "1  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "2  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "3  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "4  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "5  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 3\n",
      "len of sengment.. 1\n",
      "6  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "7  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "8  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "9  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "10  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "11  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "12  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "13  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "14  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 8\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "15  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "16  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "17  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 7\n",
      "len of sengment.. 2\n",
      "len of sengment.. 8\n",
      "18  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "19  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "20  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 6\n",
      "len of sengment.. 1\n",
      "21  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "22  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "23  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "24  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "25  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "26  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "27  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "28  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "29  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "30  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "31  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "32  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "33  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "34  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "35  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 4\n",
      "len of sengment.. 3\n",
      "36  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "37  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 5\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "38  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 7\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "39  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "40  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "41  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 2\n",
      "len of sengment.. 3\n",
      "42  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "43  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "44  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "45  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "46  batch ...\n",
      "len of sengmentS 4\n",
      "len of sengment.. 1\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "len of sengment.. 1\n",
      "47  batch ...\n",
      "len of sengmentS 2\n",
      "len of sengment.. 1\n",
      "len of sengment.. 2\n",
      "Validation Loss after epoch 2: 0.003574912193568146\n",
      "Validation Metrics after epoch 2: {'f1_a': 1.0, 'f1_b': 1.0}\n",
      "Test ***\n",
      "Test Metrics after epoch 2: {'f1_a': 1.0, 'f1_b': 1.0}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = []\n",
    "validation_metrics = []\n",
    "validation_loss = []\n",
    "for epoch in range(3):  # 3 epochs?\n",
    "    \n",
    "    print('epoch === ', epoch)\n",
    "    \n",
    "    print('Training ***')\n",
    "    train_model(model, train_dataloader, device, loss_function)\n",
    "    \n",
    "    print('Validation ***')\n",
    "    avg_val_loss, val_metrics = evaluate_model(model, val_dataloader, device, loss_function)\n",
    "    print(f'Validation Loss after epoch {epoch}: {avg_val_loss}')\n",
    "    print(f'Validation Metrics after epoch {epoch}: {val_metrics}')\n",
    "    validation_loss.append(avg_val_loss)\n",
    "    validation_metrics.append(val_metrics)\n",
    " \n",
    "    print('Test ***')\n",
    "    metrics = compute_metrics(model, test_dataloader, device)\n",
    "    test_metrics.append(metrics)\n",
    "    print(f'Test Metrics after epoch {epoch}:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60edc7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1714 MB |   18269 MB |   16992 GB |   16990 GB |\n",
      "|       from large pool |    1713 MB |   18021 MB |   16946 GB |   16945 GB |\n",
      "|       from small pool |       1 MB |     248 MB |      45 GB |      45 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1714 MB |   18269 MB |   16992 GB |   16990 GB |\n",
      "|       from large pool |    1713 MB |   18021 MB |   16946 GB |   16945 GB |\n",
      "|       from small pool |       1 MB |     248 MB |      45 GB |      45 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    1832 MB |   18560 MB |    2908 GB |    2906 GB |\n",
      "|       from large pool |    1804 MB |   18298 MB |    2882 GB |    2880 GB |\n",
      "|       from small pool |      28 MB |     262 MB |      26 GB |      26 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  119842 KB |  293031 KB |   13087 GB |   13087 GB |\n",
      "|       from large pool |   93136 KB |  277764 KB |   13023 GB |   13023 GB |\n",
      "|       from small pool |   26706 KB |   45121 KB |      63 GB |      63 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     806    |    6951    |    5430 K  |    5430 K  |\n",
      "|       from large pool |     300    |    4411    |    3747 K  |    3746 K  |\n",
      "|       from small pool |     506    |    2589    |    1683 K  |    1683 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     806    |    6951    |    5430 K  |    5430 K  |\n",
      "|       from large pool |     300    |    4411    |    3747 K  |    3746 K  |\n",
      "|       from small pool |     506    |    2589    |    1683 K  |    1683 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     123    |    1216    |  182704    |  182581    |\n",
      "|       from large pool |     109    |    1085    |  169212    |  169103    |\n",
      "|       from small pool |      14    |     131    |   13492    |   13478    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     113    |     270    |    3555 K  |    3555 K  |\n",
      "|       from large pool |      27    |      43    |    2605 K  |    2605 K  |\n",
      "|       from small pool |      86    |     242    |     950 K  |     950 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gives a readable summary of memory allocation and allows to figure the reason of CUDA running out of memory\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6fa449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f1_a': 1.0, 'f1_b': 1.0},\n",
       " {'f1_a': 1.0, 'f1_b': 1.0},\n",
       " {'f1_a': 1.0, 'f1_b': 1.0}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15eba6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f1_a': 1.0, 'f1_b': 1.0},\n",
       " {'f1_a': 1.0, 'f1_b': 1.0},\n",
       " {'f1_a': 1.0, 'f1_b': 1.0}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "341379a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.021215878862966882, 0.008341327260070025, 0.003574912193568146]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f2315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
